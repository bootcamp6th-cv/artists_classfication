{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.023969100Z",
     "start_time": "2023-12-12T03:37:45.499487300Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.059930600Z",
     "start_time": "2023-12-12T03:37:48.038617300Z"
    }
   },
   "id": "5fc1ff58a4a9d6d1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 64,\n",
    "    'EPOCHS': 100,\n",
    "    'G_LEARNING_RATE': 5e-4,\n",
    "    'D_LEARNING_RATE': 5e-4,\n",
    "    'BATCH_SIZE': 32,\n",
    "    'SEED': 2023,\n",
    "    'LATENT_SIZE': 256\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.059930600Z",
     "start_time": "2023-12-12T03:37:48.054247900Z"
    }
   },
   "id": "5c99354cb0d52004"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def clear_mem():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.075597400Z",
     "start_time": "2023-12-12T03:37:48.059930600Z"
    }
   },
   "id": "ff54722d4a8bce39"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.091352Z",
     "start_time": "2023-12-12T03:37:48.075597400Z"
    }
   },
   "id": "57142b16a76126df"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data_path = '../../data'\n",
    "train_df = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
    "train_df.loc[3896, 'artist'] = 'Titian'\n",
    "train_df.loc[3986, 'artist'] = 'Alfred Sisley'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.106999500Z",
     "start_time": "2023-12-12T03:37:48.091352Z"
    }
   },
   "id": "60ed6dfb973bafc5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_df['artist'] = le.fit_transform(train_df['artist'].values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.122814Z",
     "start_time": "2023-12-12T03:37:48.106999500Z"
    }
   },
   "id": "2ae8b183518c9394"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "   id          img_path  artist\n0   0  ./train/0000.jpg       9\n1   1  ./train/0001.jpg      48\n2   2  ./train/0002.jpg       7\n3   3  ./train/0003.jpg      10\n4   4  ./train/0004.jpg      24",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>img_path</th>\n      <th>artist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>./train/0000.jpg</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>./train/0001.jpg</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>./train/0002.jpg</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>./train/0003.jpg</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>./train/0004.jpg</td>\n      <td>24</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.sort_values(by=['id'])\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.138636600Z",
     "start_time": "2023-12-12T03:37:48.122814Z"
    }
   },
   "id": "3146f5ea6c5ce2c4"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "artist\n48    629\n10    489\n33    303\n38    233\n0     220\n35    220\n15    204\n42    181\n46    173\n30    173\n1     165\n36    142\n43    137\n2     132\n4     132\n21    121\n45    120\n32    118\n24    115\n29    101\n44     99\n37     97\n28     91\n40     85\n16     84\n9      81\n27     76\n3      74\n41     73\n18     72\n19     69\n13     65\n5      64\n26     64\n11     62\n23     61\n47     60\n39     59\n7      59\n22     52\n8      50\n12     44\n49     44\n20     42\n31     34\n34     33\n6      32\n17     30\n14     26\n25     21\nName: count, dtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['artist'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.165044100Z",
     "start_time": "2023-12-12T03:37:48.138636600Z"
    }
   },
   "id": "1e5c2de8004248c2"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_data(df, infer=False):\n",
    "    if infer:\n",
    "        return df['img_path'].apply(lambda p: os.path.join(data_path, p)).values\n",
    "    return df['img_path'].apply(lambda p: os.path.join(data_path, p)).values, df['artist'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.211934600Z",
     "start_time": "2023-12-12T03:37:48.154273400Z"
    }
   },
   "id": "db002acff51c03bd"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_img_paths, train_labels = get_data(train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.263652400Z",
     "start_time": "2023-12-12T03:37:48.165044100Z"
    }
   },
   "id": "6a8806270c88c0be"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, transforms=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            label = self.labels[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.263652400Z",
     "start_time": "2023-12-12T03:37:48.196301800Z"
    }
   },
   "id": "daa8f5c45d3e6316"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(CFG['IMG_SIZE']),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.263652400Z",
     "start_time": "2023-12-12T03:37:48.211934600Z"
    }
   },
   "id": "17b5b770a5fb4839"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1be3ec75c90>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2 ** 32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.263652400Z",
     "start_time": "2023-12-12T03:37:48.227547400Z"
    }
   },
   "id": "c69fe868589b1093"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_img_paths, train_labels, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, worker_init_fn=seed_worker, generator=g, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.294914900Z",
     "start_time": "2023-12-12T03:37:48.247870800Z"
    }
   },
   "id": "3fdc1f9a44a2408e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 모델 정의"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ad9862c8b18812b9"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# GAN 생성자 정의하기\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "             # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(CFG['LATENT_SIZE'], 512, kernel_size=4, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:48.294914900Z",
     "start_time": "2023-12-12T03:37:48.263652400Z"
    }
   },
   "id": "40df69258197e9da"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 3, 64, 64]           --\n",
      "|    └─ConvTranspose2d: 2-1              [-1, 512, 4, 4]           2,097,152\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 512, 4, 4]           1,024\n",
      "|    └─ReLU: 2-3                         [-1, 512, 4, 4]           --\n",
      "|    └─ConvTranspose2d: 2-4              [-1, 256, 8, 8]           2,097,152\n",
      "|    └─BatchNorm2d: 2-5                  [-1, 256, 8, 8]           512\n",
      "|    └─ReLU: 2-6                         [-1, 256, 8, 8]           --\n",
      "|    └─ConvTranspose2d: 2-7              [-1, 128, 16, 16]         524,288\n",
      "|    └─BatchNorm2d: 2-8                  [-1, 128, 16, 16]         256\n",
      "|    └─ReLU: 2-9                         [-1, 128, 16, 16]         --\n",
      "|    └─ConvTranspose2d: 2-10             [-1, 64, 32, 32]          131,072\n",
      "|    └─BatchNorm2d: 2-11                 [-1, 64, 32, 32]          128\n",
      "|    └─ReLU: 2-12                        [-1, 64, 32, 32]          --\n",
      "|    └─ConvTranspose2d: 2-13             [-1, 3, 64, 64]           3,072\n",
      "|    └─Tanh: 2-14                        [-1, 3, 64, 64]           --\n",
      "==========================================================================================\n",
      "Total params: 4,854,656\n",
      "Trainable params: 4,854,656\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 453.65\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.97\n",
      "Params size (MB): 18.52\n",
      "Estimated Total Size (MB): 20.49\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─Sequential: 1-1                        [-1, 3, 64, 64]           --\n|    └─ConvTranspose2d: 2-1              [-1, 512, 4, 4]           2,097,152\n|    └─BatchNorm2d: 2-2                  [-1, 512, 4, 4]           1,024\n|    └─ReLU: 2-3                         [-1, 512, 4, 4]           --\n|    └─ConvTranspose2d: 2-4              [-1, 256, 8, 8]           2,097,152\n|    └─BatchNorm2d: 2-5                  [-1, 256, 8, 8]           512\n|    └─ReLU: 2-6                         [-1, 256, 8, 8]           --\n|    └─ConvTranspose2d: 2-7              [-1, 128, 16, 16]         524,288\n|    └─BatchNorm2d: 2-8                  [-1, 128, 16, 16]         256\n|    └─ReLU: 2-9                         [-1, 128, 16, 16]         --\n|    └─ConvTranspose2d: 2-10             [-1, 64, 32, 32]          131,072\n|    └─BatchNorm2d: 2-11                 [-1, 64, 32, 32]          128\n|    └─ReLU: 2-12                        [-1, 64, 32, 32]          --\n|    └─ConvTranspose2d: 2-13             [-1, 3, 64, 64]           3,072\n|    └─Tanh: 2-14                        [-1, 3, 64, 64]           --\n==========================================================================================\nTotal params: 4,854,656\nTrainable params: 4,854,656\nNon-trainable params: 0\nTotal mult-adds (M): 453.65\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 1.97\nParams size (MB): 18.52\nEstimated Total Size (MB): 20.49\n=========================================================================================="
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(Generator(), (CFG['LATENT_SIZE'],1,1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:52.879706900Z",
     "start_time": "2023-12-12T03:37:48.279288600Z"
    }
   },
   "id": "a050ad09fb41ec0d"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# GAN 감별자 정의하기\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.disc =  nn.Sequential(            \n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(512, 1, kernel_size=4),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:52.895331400Z",
     "start_time": "2023-12-12T03:37:52.879706900Z"
    }
   },
   "id": "ffb25ace0f2d64d2"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Sequential: 1-1                        [-1, 1, 1, 1]             --\n",
      "|    └─Conv2d: 2-1                       [-1, 64, 32, 32]          3,072\n",
      "|    └─BatchNorm2d: 2-2                  [-1, 64, 32, 32]          128\n",
      "|    └─LeakyReLU: 2-3                    [-1, 64, 32, 32]          --\n",
      "|    └─Conv2d: 2-4                       [-1, 128, 16, 16]         131,072\n",
      "|    └─BatchNorm2d: 2-5                  [-1, 128, 16, 16]         256\n",
      "|    └─LeakyReLU: 2-6                    [-1, 128, 16, 16]         --\n",
      "|    └─Conv2d: 2-7                       [-1, 256, 8, 8]           524,288\n",
      "|    └─BatchNorm2d: 2-8                  [-1, 256, 8, 8]           512\n",
      "|    └─LeakyReLU: 2-9                    [-1, 256, 8, 8]           --\n",
      "|    └─Conv2d: 2-10                      [-1, 512, 4, 4]           2,097,152\n",
      "|    └─BatchNorm2d: 2-11                 [-1, 512, 4, 4]           1,024\n",
      "|    └─LeakyReLU: 2-12                   [-1, 512, 4, 4]           --\n",
      "|    └─Conv2d: 2-13                      [-1, 1, 1, 1]             8,193\n",
      "|    └─Sigmoid: 2-14                     [-1, 1, 1, 1]             --\n",
      "==========================================================================================\n",
      "Total params: 2,765,697\n",
      "Trainable params: 2,765,697\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 106.58\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 1.88\n",
      "Params size (MB): 10.55\n",
      "Estimated Total Size (MB): 12.47\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─Sequential: 1-1                        [-1, 1, 1, 1]             --\n|    └─Conv2d: 2-1                       [-1, 64, 32, 32]          3,072\n|    └─BatchNorm2d: 2-2                  [-1, 64, 32, 32]          128\n|    └─LeakyReLU: 2-3                    [-1, 64, 32, 32]          --\n|    └─Conv2d: 2-4                       [-1, 128, 16, 16]         131,072\n|    └─BatchNorm2d: 2-5                  [-1, 128, 16, 16]         256\n|    └─LeakyReLU: 2-6                    [-1, 128, 16, 16]         --\n|    └─Conv2d: 2-7                       [-1, 256, 8, 8]           524,288\n|    └─BatchNorm2d: 2-8                  [-1, 256, 8, 8]           512\n|    └─LeakyReLU: 2-9                    [-1, 256, 8, 8]           --\n|    └─Conv2d: 2-10                      [-1, 512, 4, 4]           2,097,152\n|    └─BatchNorm2d: 2-11                 [-1, 512, 4, 4]           1,024\n|    └─LeakyReLU: 2-12                   [-1, 512, 4, 4]           --\n|    └─Conv2d: 2-13                      [-1, 1, 1, 1]             8,193\n|    └─Sigmoid: 2-14                     [-1, 1, 1, 1]             --\n==========================================================================================\nTotal params: 2,765,697\nTrainable params: 2,765,697\nNon-trainable params: 0\nTotal mult-adds (M): 106.58\n==========================================================================================\nInput size (MB): 0.05\nForward/backward pass size (MB): 1.88\nParams size (MB): 10.55\nEstimated Total Size (MB): 12.47\n=========================================================================================="
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(Discriminator(), (3,64,64))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:52.973457200Z",
     "start_time": "2023-12-12T03:37:52.895331400Z"
    }
   },
   "id": "953a30dfa1892e95"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# weight 초기화\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1: # conv\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1: # batch norm\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:52.973457200Z",
     "start_time": "2023-12-12T03:37:52.957831300Z"
    }
   },
   "id": "6a0933b8495d539f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 모델 훈련"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19f542f78ebaee63"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from torch.optim.adam import Adam\n",
    "\n",
    "# 생성자 정의\n",
    "G = Generator().to(device)\n",
    "G.apply(weights_init)\n",
    "\n",
    "# 감별자 정의\n",
    "D = Discriminator().to(device)\n",
    "D.apply(weights_init)\n",
    "\n",
    "G_optim = Adam(G.parameters(), lr=CFG['G_LEARNING_RATE'], betas=(0.5, 0.999))\n",
    "D_optim = Adam(D.parameters(), lr=CFG['D_LEARNING_RATE'], betas=(0.5, 0.999))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T03:37:53.067207300Z",
     "start_time": "2023-12-12T03:37:52.973457200Z"
    }
   },
   "id": "f4b341991abd20f0"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CFG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 감별자 학습 루프\u001B[39;00m\n\u001B[0;32m      2\u001B[0m min_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m9999\u001B[39m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[43mCFG\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEPOCHS\u001B[39m\u001B[38;5;124m'\u001B[39m]):\n\u001B[0;32m      4\u001B[0m     iterator \u001B[38;5;241m=\u001B[39m tqdm(\u001B[38;5;28menumerate\u001B[39m(train_loader, \u001B[38;5;241m0\u001B[39m), total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loader))\n\u001B[0;32m      5\u001B[0m     d_loss_list \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[1;31mNameError\u001B[0m: name 'CFG' is not defined"
     ]
    }
   ],
   "source": [
    "# 감별자 학습 루프\n",
    "min_loss = 9999\n",
    "for epoch in range(CFG['EPOCHS']):\n",
    "    iterator = tqdm(enumerate(train_loader, 0), total=len(train_loader))\n",
    "    d_loss_list = []\n",
    "    g_loss_list = []\n",
    "    \n",
    "    for i, data in iterator:\n",
    "        D_optim.zero_grad()\n",
    "        label = torch.ones_like(data[1], dtype=torch.float32).to(device)\n",
    "        label_fake = torch.zeros_like(data[1], dtype=torch.float32).to(device)\n",
    "        \n",
    "        # 진짜 이미지 학습\n",
    "        real = D(data[0].to(device))\n",
    "        Dloss_real = nn.BCELoss()(torch.squeeze(real), label)\n",
    "        Dloss_real.backward()\n",
    "        \n",
    "        # 가짜 이미지 학습\n",
    "        # (N, 256, 1, 1)\n",
    "        noise = torch.randn(label.shape[0], CFG['LATENT_SIZE'], 1, 1, device=device)\n",
    "        # (N, 3, 64, 64)\n",
    "        fake = G(noise)\n",
    "        output = D(fake.detach()) # 여기서는 생성자 학습을 하지 않기 때문에 detach\n",
    "        Dloss_fake = nn.BCELoss()(torch.squeeze(output), label_fake)\n",
    "        Dloss_fake.backward()\n",
    "        \n",
    "        # 간별자의 전체 오차 계산\n",
    "        Dloss = Dloss_real + Dloss_fake\n",
    "        D_optim.step()\n",
    "        \n",
    "        # 생성자 학습\n",
    "        G_optim.zero_grad()\n",
    "        output = D(fake)\n",
    "        Gloss = nn.BCELoss()(torch.squeeze(output), label)\n",
    "        Gloss.backward()\n",
    "        G_optim.step()\n",
    "        \n",
    "        d_current_loss = Dloss.detach().cpu().item()\n",
    "        g_current_loss = Gloss.detach().cpu().item()\n",
    "        d_loss_list.append(d_current_loss)\n",
    "        g_loss_list.append(g_current_loss)\n",
    "        g_loss_list.append(Gloss.detach().item())\n",
    "        iterator.set_description(f'epoch:{epoch+1} iteration:{i+1} D_loss:{d_current_loss:.4f} G_loss:{g_current_loss:.4f}')\n",
    "    \n",
    "    d_loss_value = np.mean(d_loss_list)\n",
    "    g_loss_value = np.mean(g_loss_list)\n",
    "    total_loss = d_loss_value+g_loss_value\n",
    "    if total_loss < min_loss:\n",
    "        min_loss = total_loss\n",
    "        print(f'**epoch : {epoch+1}, total_loss : {total_loss:.4f}, d_loss : {d_loss_value:.4f}, g_loss : {g_loss_value:.4f}')\n",
    "        torch.save(G.state_dict(), os.path.join(data_path, 'Generator.pth'))\n",
    "        torch.save(D.state_dict(), os.path.join(data_path, 'Discriminator.pth'))\n",
    "    else:\n",
    "        print(f'epoch : {epoch+1}, total_loss : {total_loss:.4f}, d_loss : {d_loss_value:.4f}, g_loss : {g_loss_value:.4f}')    \n",
    "    clear_mem()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T09:42:53.821479500Z",
     "start_time": "2023-12-12T09:42:53.086939200Z"
    }
   },
   "id": "6749a24ee7f4249d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    G.load_state_dict(torch.load(os.path.join(data_path, 'Generator.pth'), map_location=device))\n",
    "    feature_vector = torch.randn(1, CFG['LATENT_SIZE'], 1, 1).to(device)\n",
    "    pred = G(feature_vector).squeeze()\n",
    "    pred = pred.permute(1,2,0).cpu().numpy()\n",
    "    plt.imshow(pred)\n",
    "    plt.title('preditected image')\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1a270e791974e47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "list(next(iter(train_loader))[0].numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1f469bc8eccfa5f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e5f0b16a435815d7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
