{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# augmentation\n",
    "* Efficient-net B2\n",
    "* Augmentation\n",
    "    - Transpose # 행렬 스왑\n",
    "    - HorizontalFlip # 좌우 반전\n",
    "    - VerticalFlip # 상하 반전\n",
    "    - ShiftScaleRotate # 랜덤하게 옮기고, scale, 회전\n",
    "    - HueSaturationValue # 빛깔, 색조, 값 변환\n",
    "    - RandomBrightnessContrast # 명도 대비\n",
    "    - ChannelShuffle # RGB 채널 간 shuffle\n",
    "    - CoarseDropout # 조그마한 검은 사각형 영역 추가\n",
    "* lr scheduler\n",
    "    - Custom CosineAnnealingWarmUpRestarts\n",
    "* k-fold\n",
    "* result\n",
    "    - train loss : \n",
    "    - validation loss : \n",
    "    - f1 score : \n",
    "    - epoch : "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35ad6a7e30f8925e"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import timm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.468933600Z",
     "start_time": "2023-12-16T16:10:34.136716800Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.517123500Z",
     "start_time": "2023-12-16T16:10:37.474619Z"
    }
   },
   "id": "5fc1ff58a4a9d6d1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 260,\n",
    "    'EPOCHS': 1000,\n",
    "    'LEARNING_RATE': 5e-6,\n",
    "    'BATCH_SIZE': 16,\n",
    "    'PATIENCE': 10,\n",
    "    'WARMUP': 5,\n",
    "    'K-FOLD': 5,\n",
    "    'FILENAME': 'kfold',\n",
    "    'SEED': 6\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.518338300Z",
     "start_time": "2023-12-16T16:10:37.503207900Z"
    }
   },
   "id": "5c99354cb0d52004"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.523699400Z",
     "start_time": "2023-12-16T16:10:37.511508600Z"
    }
   },
   "id": "57142b16a76126df"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "running_colab = 'google.colab' in str(get_ipython()) if hasattr(__builtins__,'__IPYTHON__') else False\n",
    "if running_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "if running_colab:\n",
    "    data_path = '/content/drive/MyDrive/Colab Notebooks/ai6th/data/optiver/'\n",
    "else:\n",
    "    data_path = '../../data/'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.542274800Z",
     "start_time": "2023-12-16T16:10:37.523699400Z"
    }
   },
   "id": "858b421c8c479378"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
    "df.loc[3896, 'artist'] = 'Titian'\n",
    "df.loc[3986, 'artist'] = 'Alfred Sisley'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.554367900Z",
     "start_time": "2023-12-16T16:10:37.535253500Z"
    }
   },
   "id": "60ed6dfb973bafc5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "artists = df.groupby('artist')[['id']].count().rename(columns={'id':'count'}).reset_index()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.572442100Z",
     "start_time": "2023-12-16T16:10:37.554367900Z"
    }
   },
   "id": "c031773f1ed5ca85"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['artist'] = le.fit_transform(df['artist'].values)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.588793300Z",
     "start_time": "2023-12-16T16:10:37.572442100Z"
    }
   },
   "id": "2ae8b183518c9394"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# train_df, val_df = train_test_split(df, test_size=0.2, random_state=CFG['SEED'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.608533900Z",
     "start_time": "2023-12-16T16:10:37.578187500Z"
    }
   },
   "id": "71c56b6890f87998"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# train_df = train_df.sort_values(by=['id'])\n",
    "# train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.621095700Z",
     "start_time": "2023-12-16T16:10:37.584235300Z"
    }
   },
   "id": "3146f5ea6c5ce2c4"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# val_df = val_df.sort_values(by=['id'])\n",
    "# val_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.621095700Z",
     "start_time": "2023-12-16T16:10:37.590622400Z"
    }
   },
   "id": "e4849ea7a525c8cf"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_data(df, infer=False):\n",
    "    if infer:\n",
    "        return df['img_path'].apply(lambda p: os.path.join(data_path, p)).values\n",
    "    return df['img_path'].apply(lambda p: os.path.join(data_path, p)).values, df['artist'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.621095700Z",
     "start_time": "2023-12-16T16:10:37.596705800Z"
    }
   },
   "id": "db002acff51c03bd"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, transforms=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms if transforms else ToTensor()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transforms(image=image)['image']\n",
    "        \n",
    "        if self.labels is not None:\n",
    "            label = self.labels[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.626635800Z",
     "start_time": "2023-12-16T16:10:37.613940200Z"
    }
   },
   "id": "daa8f5c45d3e6316"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE']*2,CFG['IMG_SIZE']*2),\n",
    "    A.RandomCrop(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "    A.Transpose(p=0.5), # 행렬 스왑\n",
    "    A.HorizontalFlip(p=0.5), # 좌우 반전\n",
    "    A.VerticalFlip(p=0.5), # 상하 반전\n",
    "    A.ShiftScaleRotate(p=0.5), # 랜덤하게 옮기고, scale, 회전\n",
    "    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.5), # 빛깔, 색조, 값 변환\n",
    "    A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5), # 명도 대비\n",
    "    A.ChannelShuffle(), # RGB 채널 간 shuffle\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "validation_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE']*2,CFG['IMG_SIZE']*2),\n",
    "    A.RandomCrop(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "    ToTensorV2()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.656783200Z",
     "start_time": "2023-12-16T16:10:37.621095700Z"
    }
   },
   "id": "17b5b770a5fb4839"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x2066cf66870>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2 ** 32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.675485600Z",
     "start_time": "2023-12-16T16:10:37.639416Z"
    }
   },
   "id": "c69fe868589b1093"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_classes=len(le.classes_)):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.backbone = timm.create_model('efficientnet_b2', pretrained=True, num_classes=512)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.679425900Z",
     "start_time": "2023-12-16T16:10:37.651412800Z"
    }
   },
   "id": "cd5ecc94fada5c8b"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def clear_mem():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.679425900Z",
     "start_time": "2023-12-16T16:10:37.668668400Z"
    }
   },
   "id": "ecce2baec16e71e7"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best F1 score from now: {self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "        \n",
    "        return self.early_stop"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.742119600Z",
     "start_time": "2023-12-16T16:10:37.675485600Z"
    }
   },
   "id": "51d7e36eb5ffba31"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.optim.lr_scheduler import LRScheduler\n",
    "\n",
    "class CosineAnnealingWarmUpRestarts(LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.742119600Z",
     "start_time": "2023-12-16T16:10:37.693785300Z"
    }
   },
   "id": "66827c3c4d6466cd"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id=0\n"
     ]
    }
   ],
   "source": [
    "time_now = datetime.now()\n",
    "run_id = 0# time_now.strftime(\"%Y%m%d%H%M%S\")\n",
    "os.makedirs(os.path.join(data_path, f'./runs/{run_id}'), exist_ok=True)\n",
    "print(f'{run_id=}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.742119600Z",
     "start_time": "2023-12-16T16:10:37.705720200Z"
    }
   },
   "id": "17fc703a3126967"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, criterion, train_loader, device, lr_scheduler=None):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    lr_list = []\n",
    "    # bar = tqdm(enumerate(train_loader), total = len(train_loader), desc='Train Loop')\n",
    "    for idx, (img, label) in enumerate(train_loader):\n",
    "        img, label = img.float().to(device), label.long().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model_pred = model(img)\n",
    "        loss = criterion(model_pred, label)\n",
    "\n",
    "        loss.backward()\n",
    "        if (epoch*idx)%10 == 0:\n",
    "            lr_list.append(optimizer.param_groups[0]['lr'])\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        # bar.set_postfix(train_loss = f'{loss.item():.4f}', lr = f\"{optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        if lr_scheduler:\n",
    "            lr_scheduler.step()\n",
    "    return np.mean(train_loss), lr_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.742119600Z",
     "start_time": "2023-12-16T16:10:37.734365700Z"
    }
   },
   "id": "8837f76bd55e594f"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def competition_metric(true, pred):\n",
    "    return f1_score(true, pred, average=\"macro\")\n",
    "\n",
    "def validation(model, criterion, test_loader, device):\n",
    "    model.eval()\n",
    "    \n",
    "    model_preds = []\n",
    "    true_labels = []\n",
    "    \n",
    "    val_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for img, label in iter(test_loader):\n",
    "            img, label = img.float().to(device), label.long().to(device)\n",
    "            \n",
    "            model_pred = model(img)\n",
    "            \n",
    "            loss = criterion(model_pred, label)\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "            \n",
    "            model_preds += model_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += label.detach().cpu().numpy().tolist()\n",
    "        \n",
    "    val_f1 = competition_metric(true_labels, model_preds)\n",
    "    return np.mean(val_loss), val_f1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.818567800Z",
     "start_time": "2023-12-16T16:10:37.742119600Z"
    }
   },
   "id": "6e0713601b2fa53a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def train_epoch(k, model, optimizer, train_loader, test_loader, lr_scheduler, device):\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    early_stopping = EarlyStopping(patience=CFG['PATIENCE'], verbose=True)\n",
    "    \n",
    "    best_score = 0\n",
    "    lr_list = []\n",
    "    train_loss_list, val_loss_list = [], []\n",
    "    \n",
    "    for epoch in range(1,CFG[\"EPOCHS\"]+1):\n",
    "        tr_loss, lr_ = train(epoch, model, optimizer, criterion, train_loader, device, lr_scheduler)\n",
    "        val_loss, val_score = validation(model, criterion, test_loader, device)\n",
    "        train_loss_list.append(tr_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "        \n",
    "        if lr_scheduler is not None:\n",
    "            lr_list.extend(lr_)\n",
    "            \n",
    "        if best_score < val_score:\n",
    "            print(f'**Epoch [{k}-{epoch}], Train Loss : [{tr_loss:.5f}] Val Loss : [{val_loss:.5f}] Val F1 Score : [{val_score:.5f}]')\n",
    "            best_score = val_score\n",
    "            torch.save(model, os.path.join(data_path, f'runs/{run_id}/best_model_{k}.pt'))\n",
    "        else:\n",
    "            print(f'Epoch [{k}-{epoch}], Train Loss : [{tr_loss:.5f}] Val Loss : [{val_loss:.5f}] Val F1 Score : [{val_score:.5f}]')\n",
    "        clear_mem()\n",
    "        if early_stopping(val_score):\n",
    "            print(f'Epoch [{k}-{epoch}], early stopping')\n",
    "            break\n",
    "    if lr_list:\n",
    "        return (train_loss_list, val_loss_list, val_score, lr_list)\n",
    "    else:\n",
    "        return (train_loss_list, val_loss_list, val_score, None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.885901300Z",
     "start_time": "2023-12-16T16:10:37.772149400Z"
    }
   },
   "id": "533c937dd1370a10"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def k_fold(k): # k-fold\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=False)\n",
    "    f1_sum = 0\n",
    "    for k_, (train_index, valid_index) in enumerate(skf.split(df, df['artist'])):\n",
    "        print(f'{k_}-fold start')\n",
    "        \n",
    "        train_img_paths, train_labels = get_data(df.iloc[train_index])\n",
    "        val_img_paths, val_labels = get_data(df.iloc[valid_index])\n",
    "        train_dataset = CustomDataset(train_img_paths, train_labels, train_transform)\n",
    "        train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, worker_init_fn=seed_worker, generator=g, num_workers=0)\n",
    "        val_dataset = CustomDataset(val_img_paths, val_labels, validation_transform)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, worker_init_fn=seed_worker, generator=g, num_workers=0)\n",
    "        \n",
    "        model = BaseModel()\n",
    "        model.eval()\n",
    "        optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG['LEARNING_RATE'])\n",
    "        # lr : 5epochs 동안 0.01->0\n",
    "        lr_scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=CFG['WARMUP']*len(train_loader), T_mult=2, eta_max=0.001, T_up=50, gamma=0.5)\n",
    "        _, _, f1_score, _ = train_epoch(k_, model, optimizer, train_loader, val_loader, lr_scheduler, device)\n",
    "        f1_sum += f1_score\n",
    "    return f1_sum/k"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T16:10:37.991014400Z",
     "start_time": "2023-12-16T16:10:37.788392900Z"
    }
   },
   "id": "ef23a282d7caf6e6"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-fold start\n",
      "**Epoch [0-1], Train Loss : [2.94579] Val Loss : [2.34241] Val F1 Score : [0.17453]\n",
      "**Epoch [0-2], Train Loss : [2.31488] Val Loss : [1.74371] Val F1 Score : [0.35594]\n",
      "**Epoch [0-3], Train Loss : [1.81780] Val Loss : [1.44156] Val F1 Score : [0.45210]\n",
      "**Epoch [0-4], Train Loss : [1.43229] Val Loss : [1.21080] Val F1 Score : [0.51861]\n",
      "**Epoch [0-5], Train Loss : [1.16349] Val Loss : [1.17128] Val F1 Score : [0.54541]\n",
      "Epoch [0-6], Train Loss : [1.44334] Val Loss : [1.45921] Val F1 Score : [0.45809]\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best F1 score from now: 0.5454126987740568\n",
      "Epoch [0-7], Train Loss : [1.37793] Val Loss : [1.35438] Val F1 Score : [0.52037]\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best F1 score from now: 0.5454126987740568\n",
      "**Epoch [0-8], Train Loss : [1.24712] Val Loss : [1.19164] Val F1 Score : [0.56644]\n",
      "**Epoch [0-9], Train Loss : [1.05079] Val Loss : [1.16760] Val F1 Score : [0.59867]\n",
      "**Epoch [0-10], Train Loss : [0.89049] Val Loss : [1.08669] Val F1 Score : [0.61642]\n",
      "**Epoch [0-11], Train Loss : [0.73763] Val Loss : [1.10645] Val F1 Score : [0.64150]\n",
      "**Epoch [0-12], Train Loss : [0.60430] Val Loss : [1.02245] Val F1 Score : [0.66226]\n",
      "**Epoch [0-13], Train Loss : [0.50760] Val Loss : [0.98869] Val F1 Score : [0.68624]\n",
      "**Epoch [0-14], Train Loss : [0.44987] Val Loss : [0.96790] Val F1 Score : [0.68992]\n",
      "Epoch [0-15], Train Loss : [0.42560] Val Loss : [1.00353] Val F1 Score : [0.67351]\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best F1 score from now: 0.6899218465703669\n",
      "Epoch [0-16], Train Loss : [0.58177] Val Loss : [1.13243] Val F1 Score : [0.64019]\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best F1 score from now: 0.6899218465703669\n",
      "Epoch [0-17], Train Loss : [0.57767] Val Loss : [1.20101] Val F1 Score : [0.62530]\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Best F1 score from now: 0.6899218465703669\n",
      "Epoch [0-18], Train Loss : [0.52464] Val Loss : [1.20952] Val F1 Score : [0.63721]\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Best F1 score from now: 0.6899218465703669\n",
      "Epoch [0-19], Train Loss : [0.46739] Val Loss : [1.15959] Val F1 Score : [0.64095]\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Best F1 score from now: 0.6899218465703669\n",
      "Epoch [0-20], Train Loss : [0.41146] Val Loss : [1.21220] Val F1 Score : [0.64190]\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Best F1 score from now: 0.6899218465703669\n",
      "Epoch [0-21], Train Loss : [0.37889] Val Loss : [1.13763] Val F1 Score : [0.65684]\n",
      "EarlyStopping counter: 7 out of 10\n",
      "Best F1 score from now: 0.6899218465703669\n",
      "Epoch [0-22], Train Loss : [0.29569] Val Loss : [1.22666] Val F1 Score : [0.65878]\n",
      "EarlyStopping counter: 8 out of 10\n",
      "Best F1 score from now: 0.6899218465703669\n",
      "Epoch [0-23], Train Loss : [0.27776] Val Loss : [1.13415] Val F1 Score : [0.64604]\n",
      "EarlyStopping counter: 9 out of 10\n",
      "Best F1 score from now: 0.6899218465703669\n",
      "Epoch [0-24], Train Loss : [0.25563] Val Loss : [1.17150] Val F1 Score : [0.68273]\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Best F1 score from now: 0.6899218465703669\n",
      "Epoch [0-24], early stopping\n",
      "1-fold start\n",
      "**Epoch [1-1], Train Loss : [2.98655] Val Loss : [2.22966] Val F1 Score : [0.21796]\n",
      "**Epoch [1-2], Train Loss : [2.31030] Val Loss : [1.78512] Val F1 Score : [0.34941]\n",
      "**Epoch [1-3], Train Loss : [1.87415] Val Loss : [1.41098] Val F1 Score : [0.46412]\n",
      "**Epoch [1-4], Train Loss : [1.42757] Val Loss : [1.19426] Val F1 Score : [0.53534]\n",
      "**Epoch [1-5], Train Loss : [1.18069] Val Loss : [1.16228] Val F1 Score : [0.55919]\n",
      "Epoch [1-6], Train Loss : [1.44764] Val Loss : [1.43086] Val F1 Score : [0.47800]\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best F1 score from now: 0.559188764754853\n",
      "Epoch [1-7], Train Loss : [1.40578] Val Loss : [1.33901] Val F1 Score : [0.53317]\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best F1 score from now: 0.559188764754853\n",
      "**Epoch [1-8], Train Loss : [1.22251] Val Loss : [1.18545] Val F1 Score : [0.57635]\n",
      "**Epoch [1-9], Train Loss : [1.05752] Val Loss : [1.08773] Val F1 Score : [0.60934]\n",
      "**Epoch [1-10], Train Loss : [0.91519] Val Loss : [1.03018] Val F1 Score : [0.62371]\n",
      "**Epoch [1-11], Train Loss : [0.75428] Val Loss : [1.05621] Val F1 Score : [0.63117]\n",
      "**Epoch [1-12], Train Loss : [0.60299] Val Loss : [0.94351] Val F1 Score : [0.66166]\n",
      "Epoch [1-13], Train Loss : [0.52247] Val Loss : [0.93405] Val F1 Score : [0.65961]\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best F1 score from now: 0.6616646456077814\n",
      "**Epoch [1-14], Train Loss : [0.44380] Val Loss : [0.87686] Val F1 Score : [0.68451]\n",
      "Epoch [1-15], Train Loss : [0.41547] Val Loss : [0.91516] Val F1 Score : [0.67734]\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best F1 score from now: 0.6845069575470157\n",
      "Epoch [1-16], Train Loss : [0.61458] Val Loss : [1.07099] Val F1 Score : [0.61735]\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best F1 score from now: 0.6845069575470157\n",
      "Epoch [1-17], Train Loss : [0.57026] Val Loss : [1.06702] Val F1 Score : [0.63700]\n",
      "EarlyStopping counter: 3 out of 10\n",
      "Best F1 score from now: 0.6845069575470157\n",
      "Epoch [1-18], Train Loss : [0.52339] Val Loss : [1.06805] Val F1 Score : [0.63949]\n",
      "EarlyStopping counter: 4 out of 10\n",
      "Best F1 score from now: 0.6845069575470157\n",
      "Epoch [1-19], Train Loss : [0.48013] Val Loss : [1.15422] Val F1 Score : [0.65193]\n",
      "EarlyStopping counter: 5 out of 10\n",
      "Best F1 score from now: 0.6845069575470157\n",
      "Epoch [1-20], Train Loss : [0.43768] Val Loss : [1.13378] Val F1 Score : [0.64252]\n",
      "EarlyStopping counter: 6 out of 10\n",
      "Best F1 score from now: 0.6845069575470157\n",
      "**Epoch [1-21], Train Loss : [0.40085] Val Loss : [0.99831] Val F1 Score : [0.68749]\n",
      "Epoch [1-22], Train Loss : [0.33861] Val Loss : [1.06154] Val F1 Score : [0.64597]\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best F1 score from now: 0.6874947771984161\n",
      "Epoch [1-23], Train Loss : [0.29623] Val Loss : [1.05611] Val F1 Score : [0.67682]\n",
      "EarlyStopping counter: 2 out of 10\n",
      "Best F1 score from now: 0.6874947771984161\n",
      "**Epoch [1-24], Train Loss : [0.26304] Val Loss : [0.96656] Val F1 Score : [0.68771]\n",
      "Epoch [1-25], Train Loss : [0.21018] Val Loss : [1.07979] Val F1 Score : [0.66857]\n",
      "EarlyStopping counter: 1 out of 10\n",
      "Best F1 score from now: 0.6877125612874455\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m f1_score \u001B[38;5;241m=\u001B[39m \u001B[43mk_fold\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCFG\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mK-FOLD\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(f1_score)\n",
      "Cell \u001B[1;32mIn[24], line 19\u001B[0m, in \u001B[0;36mk_fold\u001B[1;34m(k)\u001B[0m\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;66;03m# lr : 5epochs 동안 0.01->0\u001B[39;00m\n\u001B[0;32m     18\u001B[0m     lr_scheduler \u001B[38;5;241m=\u001B[39m CosineAnnealingWarmUpRestarts(optimizer, T_0\u001B[38;5;241m=\u001B[39mCFG[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWARMUP\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlen\u001B[39m(train_loader), T_mult\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, eta_max\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m, T_up\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n\u001B[1;32m---> 19\u001B[0m     _, _, f1_score, _ \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mk_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_scheduler\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m     f1_sum \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m f1_score\n\u001B[0;32m     21\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f1_sum\u001B[38;5;241m/\u001B[39mk\n",
      "Cell \u001B[1;32mIn[23], line 12\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[1;34m(k, model, optimizer, train_loader, test_loader, lr_scheduler, device)\u001B[0m\n\u001B[0;32m      9\u001B[0m train_loss_list, val_loss_list \u001B[38;5;241m=\u001B[39m [], []\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m,CFG[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEPOCHS\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m---> 12\u001B[0m     tr_loss, lr_ \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr_scheduler\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m     val_loss, val_score \u001B[38;5;241m=\u001B[39m validation(model, criterion, test_loader, device)\n\u001B[0;32m     14\u001B[0m     train_loss_list\u001B[38;5;241m.\u001B[39mappend(tr_loss)\n",
      "Cell \u001B[1;32mIn[21], line 6\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(epoch, model, optimizer, criterion, train_loader, device, lr_scheduler)\u001B[0m\n\u001B[0;32m      4\u001B[0m lr_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# bar = tqdm(enumerate(train_loader), total = len(train_loader), desc='Train Loop')\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, (img, label) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[0;32m      7\u001B[0m     img, label \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mto(device), label\u001B[38;5;241m.\u001B[39mlong()\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      9\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\artists_classification\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\artists_classification\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    672\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    673\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 674\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    675\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    676\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\artists_classification\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\artists_classification\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__(possibly_batched_index)\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n",
      "Cell \u001B[1;32mIn[13], line 12\u001B[0m, in \u001B[0;36mCustomDataset.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, index):\n\u001B[0;32m     11\u001B[0m     img_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimg_paths[index]\n\u001B[1;32m---> 12\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[43mcv2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m     image \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mcvtColor(image, cv2\u001B[38;5;241m.\u001B[39mCOLOR_BGR2RGB)\n\u001B[0;32m     14\u001B[0m     image \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms(image\u001B[38;5;241m=\u001B[39mimage)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "f1_score = k_fold(CFG['K-FOLD'])\n",
    "print(f1_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T17:27:38.849633300Z",
     "start_time": "2023-12-16T16:10:37.805053700Z"
    }
   },
   "id": "9ecf48ad115665dd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(os.path.join(data_path, './test.csv'))\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-16T17:27:38.835271200Z"
    }
   },
   "id": "9c8fff1a450556ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_img_paths = get_data(test_df, infer=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-16T17:27:38.840377700Z"
    }
   },
   "id": "6a50c39d21de27ed"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_img_paths, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-16T17:27:38.845375500Z"
    }
   },
   "id": "66859c2e35131aae"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    model_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, img in enumerate(test_loader):\n",
    "            img = img.float().to(device)\n",
    "            \n",
    "            model_pred = model(img).detach().cpu()\n",
    "            model_pred = F.softmax(model_pred, dim=1)\n",
    "            model_preds.extend(model_pred.numpy().tolist())\n",
    "    \n",
    "    print('Done.')\n",
    "    return model_preds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T17:27:38.860617600Z",
     "start_time": "2023-12-16T17:27:38.852635600Z"
    }
   },
   "id": "60aba723872ee62e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CFG['K-FOLD']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-16T17:27:38.855616100Z"
    }
   },
   "id": "927e863163381d08"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df = pd.DataFrame(np.zeros((test_df.shape[0], len(le.classes_))))\n",
    "for k_ in range(CFG['K-FOLD']):\n",
    "    checkpoint = os.path.join(data_path, f'runs/{run_id}/best_model_{k_}.pt')\n",
    "    print(f'{k_}-fold CHECKPOINT LOADED: {checkpoint}')\n",
    "    infer_model = torch.load(checkpoint)\n",
    "    infer_model.to(device)\n",
    "    infer_model.eval()\n",
    "    result_df += pd.DataFrame(inference(infer_model, test_loader, device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T17:27:38.861576300Z",
     "start_time": "2023-12-16T17:27:38.861270100Z"
    }
   },
   "id": "605d913e0df9b6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-16T17:27:38.941286100Z"
    }
   },
   "id": "9df29cbb4653101f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = result_df.idxmax(axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-16T17:27:38.941286100Z"
    }
   },
   "id": "c1cc27ee0e75b6fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = le.inverse_transform(preds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-16T17:27:38.946517300Z",
     "start_time": "2023-12-16T17:27:38.941286100Z"
    }
   },
   "id": "37b7f04a0b4de44f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submit = pd.read_csv(os.path.join(data_path, './sample_submission.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-16T17:27:38.941286100Z"
    }
   },
   "id": "fe59292099a9b96e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submit['artist'] = preds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-16T17:27:38.941286100Z"
    }
   },
   "id": "8582475a6cb3db6f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submit.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-16T17:27:38.941286100Z"
    }
   },
   "id": "15bd98c5d6b59bf4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submit.to_csv(os.path.join(data_path, f\"./submit_{CFG['FILENAME']}.csv\"), index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-16T17:27:38.941286100Z"
    }
   },
   "id": "eed3cb0dc59f47f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-12-16T17:27:38.941286100Z"
    }
   },
   "id": "d3ed2b836c4e558b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
