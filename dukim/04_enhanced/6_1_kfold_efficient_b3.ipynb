{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Efficientnet b3\n",
    "* Efficientnet b3 적용\n",
    "    - Efficientnet b3\n",
    "    - dropout, normalization 적용\n",
    "    - GELU\n",
    "* Augmentation\n",
    "    - Transpose # 행렬 스왑\n",
    "    - HorizontalFlip # 좌우 반전\n",
    "    - VerticalFlip # 상하 반전\n",
    "    - CoarseDrop\n",
    "* lr scheduler\n",
    "    - Custom CosineAnnealingWarmUpRestarts\n",
    "    - T_hold : min_lr * 10 적용\n",
    "* optimizer\n",
    "    - AdamW\n",
    "* focal loss 적용\n",
    "* cutmix\n",
    "    - lam `0~0.25`, `0.75~1`\n",
    "* k-fold\n",
    "* pacience \n",
    "    - 10 -> 12\n",
    "* result\n",
    "    - fold0 : Epoch [0-47], lr : [0.000010], Train Loss : [0.4373], Val Loss : [0.3877], Val F1 Score : [0.8103]\n",
    "    - fold1 : Epoch [1-43], lr : [0.000058], Train Loss : [0.3590], Val Loss : [0.3707], Val F1 Score : [0.8233]\n",
    "    - fold2 : Epoch [2-42], lr : [0.000006], Train Loss : [0.4004], Val Loss : [0.4116], Val F1 Score : [0.8271]\n",
    "    - fold3 : Epoch [3-18], lr : [0.000006], Train Loss : [0.5786], Val Loss : [0.4356], Val F1 Score : [0.7953]\n",
    "    - fold4 : Epoch [4-34], lr : [0.000020], Train Loss : [0.4358], Val Loss : [0.4252], Val F1 Score : [0.8072]\n",
    "        - 40587\n",
    "        - public 점수 : 0.8351786096\n",
    "        - private 점수 : 0.8365907466\n"
   ],
   "metadata": {
    "collapsed": false,
    "id": "35ad6a7e30f8925e"
   },
   "id": "35ad6a7e30f8925e"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import EfficientNetModel\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ],
   "metadata": {
    "id": "initial_id",
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:13.201600600Z",
     "start_time": "2023-12-26T23:23:09.598021800Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ],
   "metadata": {
    "id": "5fc1ff58a4a9d6d1",
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:14.756913700Z",
     "start_time": "2023-12-26T23:23:14.746909Z"
    }
   },
   "id": "5fc1ff58a4a9d6d1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 300,\n",
    "    'EPOCHS': 1000,\n",
    "    'LEARNING_RATE': 6e-6,\n",
    "    'BATCH_SIZE': 16,\n",
    "    'PATIENCE': 12,\n",
    "    'WARMUP': 6,\n",
    "    'K-FOLD': 5,\n",
    "    'FILENAME': 'kfold_efficientnet',\n",
    "    'SEED': 6\n",
    "}"
   ],
   "metadata": {
    "id": "5c99354cb0d52004",
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:14.772246600Z",
     "start_time": "2023-12-26T23:23:14.750913600Z"
    }
   },
   "id": "5c99354cb0d52004"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ],
   "metadata": {
    "id": "57142b16a76126df",
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:14.786245900Z",
     "start_time": "2023-12-26T23:23:14.768247200Z"
    }
   },
   "id": "57142b16a76126df"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "running_colab = 'google.colab' in str(get_ipython()) if hasattr(__builtins__,'__IPYTHON__') else False\n",
    "if running_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "if running_colab:\n",
    "    data_path = '/content/drive/MyDrive/Colab Notebooks/ai6th/data/optiver/'\n",
    "else:\n",
    "    data_path = '../../data/'"
   ],
   "metadata": {
    "id": "858b421c8c479378",
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:14.825256900Z",
     "start_time": "2023-12-26T23:23:14.780247900Z"
    }
   },
   "id": "858b421c8c479378"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   id          img_path            artist\n0   0  ./train/0000.jpg   Diego Velazquez\n1   1  ./train/0001.jpg  Vincent van Gogh\n2   2  ./train/0002.jpg      Claude Monet\n3   3  ./train/0003.jpg       Edgar Degas\n4   4  ./train/0004.jpg  Hieronymus Bosch",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>img_path</th>\n      <th>artist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>./train/0000.jpg</td>\n      <td>Diego Velazquez</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>./train/0001.jpg</td>\n      <td>Vincent van Gogh</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>./train/0002.jpg</td>\n      <td>Claude Monet</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>./train/0003.jpg</td>\n      <td>Edgar Degas</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>./train/0004.jpg</td>\n      <td>Hieronymus Bosch</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
    "df.loc[3896, 'artist'] = 'Titian'\n",
    "df.loc[3986, 'artist'] = 'Alfred Sisley'\n",
    "df.head()"
   ],
   "metadata": {
    "id": "60ed6dfb973bafc5",
    "outputId": "4728b14b-8f13-4f9c-c371-ba35fb016e9c",
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:14.848196200Z",
     "start_time": "2023-12-26T23:23:14.797247700Z"
    }
   },
   "id": "60ed6dfb973bafc5"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "artists = df.groupby('artist')[['id']].count().rename(columns={'id':'count'}).reset_index()"
   ],
   "metadata": {
    "id": "c031773f1ed5ca85",
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:14.851185500Z",
     "start_time": "2023-12-26T23:23:14.830179900Z"
    }
   },
   "id": "c031773f1ed5ca85"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "le = preprocessing.LabelEncoder()\n",
    "df['artist'] = le.fit_transform(df['artist'].values)"
   ],
   "metadata": {
    "id": "2ae8b183518c9394",
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:14.883714900Z",
     "start_time": "2023-12-26T23:23:14.848196200Z"
    }
   },
   "id": "2ae8b183518c9394"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def get_data(df, infer=False):\n",
    "    if infer:\n",
    "        return df['img_path'].apply(lambda p: os.path.join(data_path, p)).values\n",
    "    return df['img_path'].apply(lambda p: os.path.join(data_path, p)).values, df['artist'].values"
   ],
   "metadata": {
    "id": "db002acff51c03bd",
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:14.885711200Z",
     "start_time": "2023-12-26T23:23:14.862185800Z"
    }
   },
   "id": "db002acff51c03bd"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_paths, labels, transforms=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms if transforms else ToTensor()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.img_paths[index]\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transforms(image=image)['image']\n",
    "\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[index]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)"
   ],
   "metadata": {
    "id": "daa8f5c45d3e6316",
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:14.920713500Z",
     "start_time": "2023-12-26T23:23:14.878703300Z"
    }
   },
   "id": "daa8f5c45d3e6316"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE']*2,CFG['IMG_SIZE']*2),\n",
    "    A.RandomCrop(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "    A.Transpose(p=0.5), # 행렬 스왑\n",
    "    A.HorizontalFlip(p=0.5), # 좌우 반전\n",
    "    A.VerticalFlip(p=0.5), # 상하 반전\n",
    "    # A.ShiftScaleRotate(p=0.5), # 랜덤하게 옮기고, scale, 회전\n",
    "    # A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=20, val_shift_limit=20, p=0.5), # 빛깔, 색조, 값 변환\n",
    "    # A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5), # 명도 대비\n",
    "    # A.ChannelShuffle(), # RGB 채널 간 shuffle\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "    A.CoarseDropout(p=0.5),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "validation_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE']*2,CFG['IMG_SIZE']*2),\n",
    "    A.RandomCrop(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "    ToTensorV2()\n",
    "])"
   ],
   "metadata": {
    "id": "17b5b770a5fb4839",
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:15.082860Z",
     "start_time": "2023-12-26T23:23:14.896705400Z"
    }
   },
   "id": "17b5b770a5fb4839"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1d4a3aaaed0>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2 ** 32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)"
   ],
   "metadata": {
    "id": "c69fe868589b1093",
    "outputId": "b056aadb-a0a7-4dea-b3b0-06cddb2d2d5a",
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:15.090850800Z",
     "start_time": "2023-12-26T23:23:14.908702900Z"
    }
   },
   "id": "c69fe868589b1093"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class EfficientNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=len(le.classes_)):\n",
    "        super(EfficientNetModel, self).__init__()\n",
    "        self.backbone = timm.create_model('efficientnet_b3', pretrained=True, num_classes=512)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.LayerNorm(512),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ],
   "metadata": {
    "id": "cd5ecc94fada5c8b",
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:15.090850800Z",
     "start_time": "2023-12-26T23:23:14.925702900Z"
    }
   },
   "id": "cd5ecc94fada5c8b"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Layer (type:depth-idx)                             Output Shape              Param #\n",
      "====================================================================================================\n",
      "├─EfficientNet: 1-1                                [-1, 512]                 --\n",
      "|    └─Conv2d: 2-1                                 [-1, 40, 150, 150]        1,080\n",
      "|    └─BatchNormAct2d: 2-2                         [-1, 40, 150, 150]        --\n",
      "|    |    └─Identity: 3-1                          [-1, 40, 150, 150]        --\n",
      "|    |    └─SiLU: 3-2                              [-1, 40, 150, 150]        --\n",
      "|    └─Sequential: 2-3                             [-1, 384, 10, 10]         --\n",
      "|    |    └─Sequential: 3-3                        [-1, 24, 150, 150]        3,504\n",
      "|    |    └─Sequential: 3-4                        [-1, 32, 75, 75]          48,118\n",
      "|    |    └─Sequential: 3-5                        [-1, 48, 38, 38]          110,912\n",
      "|    |    └─Sequential: 3-6                        [-1, 96, 19, 19]          638,700\n",
      "|    |    └─Sequential: 3-7                        [-1, 136, 19, 19]         1,387,760\n",
      "|    |    └─Sequential: 3-8                        [-1, 232, 10, 10]         4,628,964\n",
      "|    |    └─Sequential: 3-9                        [-1, 384, 10, 10]         3,284,218\n",
      "|    └─Conv2d: 2-4                                 [-1, 1536, 10, 10]        589,824\n",
      "|    └─BatchNormAct2d: 2-5                         [-1, 1536, 10, 10]        --\n",
      "|    |    └─Identity: 3-10                         [-1, 1536, 10, 10]        --\n",
      "|    |    └─SiLU: 3-11                             [-1, 1536, 10, 10]        --\n",
      "|    └─SelectAdaptivePool2d: 2-6                   [-1, 1536]                --\n",
      "|    |    └─AdaptiveAvgPool2d: 3-12                [-1, 1536, 1, 1]          --\n",
      "|    |    └─Flatten: 3-13                          [-1, 1536]                --\n",
      "|    └─Linear: 2-7                                 [-1, 512]                 786,944\n",
      "├─Sequential: 1-2                                  [-1, 50]                  --\n",
      "|    └─LayerNorm: 2-8                              [-1, 512]                 1,024\n",
      "|    └─GELU: 2-9                                   [-1, 512]                 --\n",
      "|    └─Dropout: 2-10                               [-1, 512]                 --\n",
      "|    └─Linear: 2-11                                [-1, 50]                  25,650\n",
      "====================================================================================================\n",
      "Total params: 11,506,698\n",
      "Trainable params: 11,506,698\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 125.66\n",
      "====================================================================================================\n",
      "Input size (MB): 1.03\n",
      "Forward/backward pass size (MB): 8.05\n",
      "Params size (MB): 43.89\n",
      "Estimated Total Size (MB): 52.97\n",
      "====================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "====================================================================================================\nLayer (type:depth-idx)                             Output Shape              Param #\n====================================================================================================\n├─EfficientNet: 1-1                                [-1, 512]                 --\n|    └─Conv2d: 2-1                                 [-1, 40, 150, 150]        1,080\n|    └─BatchNormAct2d: 2-2                         [-1, 40, 150, 150]        --\n|    |    └─Identity: 3-1                          [-1, 40, 150, 150]        --\n|    |    └─SiLU: 3-2                              [-1, 40, 150, 150]        --\n|    └─Sequential: 2-3                             [-1, 384, 10, 10]         --\n|    |    └─Sequential: 3-3                        [-1, 24, 150, 150]        3,504\n|    |    └─Sequential: 3-4                        [-1, 32, 75, 75]          48,118\n|    |    └─Sequential: 3-5                        [-1, 48, 38, 38]          110,912\n|    |    └─Sequential: 3-6                        [-1, 96, 19, 19]          638,700\n|    |    └─Sequential: 3-7                        [-1, 136, 19, 19]         1,387,760\n|    |    └─Sequential: 3-8                        [-1, 232, 10, 10]         4,628,964\n|    |    └─Sequential: 3-9                        [-1, 384, 10, 10]         3,284,218\n|    └─Conv2d: 2-4                                 [-1, 1536, 10, 10]        589,824\n|    └─BatchNormAct2d: 2-5                         [-1, 1536, 10, 10]        --\n|    |    └─Identity: 3-10                         [-1, 1536, 10, 10]        --\n|    |    └─SiLU: 3-11                             [-1, 1536, 10, 10]        --\n|    └─SelectAdaptivePool2d: 2-6                   [-1, 1536]                --\n|    |    └─AdaptiveAvgPool2d: 3-12                [-1, 1536, 1, 1]          --\n|    |    └─Flatten: 3-13                          [-1, 1536]                --\n|    └─Linear: 2-7                                 [-1, 512]                 786,944\n├─Sequential: 1-2                                  [-1, 50]                  --\n|    └─LayerNorm: 2-8                              [-1, 512]                 1,024\n|    └─GELU: 2-9                                   [-1, 512]                 --\n|    └─Dropout: 2-10                               [-1, 512]                 --\n|    └─Linear: 2-11                                [-1, 50]                  25,650\n====================================================================================================\nTotal params: 11,506,698\nTrainable params: 11,506,698\nNon-trainable params: 0\nTotal mult-adds (M): 125.66\n====================================================================================================\nInput size (MB): 1.03\nForward/backward pass size (MB): 8.05\nParams size (MB): 43.89\nEstimated Total Size (MB): 52.97\n===================================================================================================="
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = EfficientNetModel()\n",
    "summary(model, (3,300,300))"
   ],
   "metadata": {
    "id": "67da3204ab03efc8",
    "outputId": "92244e7c-6318-479a-c134-c2b88c672fd3",
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:19.185939200Z",
     "start_time": "2023-12-26T23:23:14.940704500Z"
    }
   },
   "id": "67da3204ab03efc8"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def clear_mem():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:19.241273900Z",
     "start_time": "2023-12-26T23:23:19.182819Z"
    }
   },
   "id": "ecce2baec16e71e7"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            print(f'Best F1 score from now: {self.best_score}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "        return self.early_stop"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:19.255300500Z",
     "start_time": "2023-12-26T23:23:19.199274200Z"
    }
   },
   "id": "51d7e36eb5ffba31"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def rand_bbox(size, lam):   # size : [B, C, W, H]\n",
    "    W = size[2] # 이미지의 width\n",
    "    H = size[3] # 이미지의 height\n",
    "    cut_rat = np.sqrt(1. - lam)  # 패치 크기의 비율 정하기\n",
    "    cut_w = np.int32(W * cut_rat)  # 패치의 너비\n",
    "    cut_h = np.int32(H * cut_rat)  # 패치의 높이\n",
    "\n",
    "    # uniform\n",
    "    # 기존 이미지의 크기에서 랜덤하게 값을 가져옵니다.(중간 좌표 추출)\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    # 패치 부분에 대한 좌표값을 추출합니다.\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    return bbx1, bby1, bbx2, bby2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:19.257299800Z",
     "start_time": "2023-12-26T23:23:19.215276300Z"
    }
   },
   "id": "ce87987e0b603241"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.optim.lr_scheduler import LRScheduler\n",
    "\n",
    "class CosineAnnealingWarmUpRestarts(LRScheduler):\n",
    "    def __init__(self, optimizer, T_0, T_mult=1, eta_max=0.1, T_up=0, gamma=1., last_epoch=-1, T_hold=5e-5):\n",
    "        if T_0 <= 0 or not isinstance(T_0, int):\n",
    "            raise ValueError(\"Expected positive integer T_0, but got {}\".format(T_0))\n",
    "        if T_mult < 1 or not isinstance(T_mult, int):\n",
    "            raise ValueError(\"Expected integer T_mult >= 1, but got {}\".format(T_mult))\n",
    "        if T_up < 0 or not isinstance(T_up, int):\n",
    "            raise ValueError(\"Expected positive integer T_up, but got {}\".format(T_up))\n",
    "        self.T_0 = T_0\n",
    "        self.T_mult = T_mult\n",
    "        self.base_eta_max = eta_max\n",
    "        self.eta_max = eta_max\n",
    "        self.T_up = T_up\n",
    "        self.T_i = T_0\n",
    "        self.gamma = gamma\n",
    "        self.cycle = 0\n",
    "        self.T_cur = last_epoch\n",
    "        self.T_hold = T_hold # custom\n",
    "        super(CosineAnnealingWarmUpRestarts, self).__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.T_cur == -1:\n",
    "            return self.base_lrs\n",
    "        elif self.T_cur < self.T_up:\n",
    "            return [(self.eta_max - base_lr)*self.T_cur / self.T_up + base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr + (self.eta_max - base_lr) * (1 + math.cos(math.pi * (self.T_cur-self.T_up) / (self.T_i - self.T_up))) / 2\n",
    "                    for base_lr in self.base_lrs]\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if epoch is None:\n",
    "            epoch = self.last_epoch + 1\n",
    "            self.T_cur = self.T_cur + 1\n",
    "            if self.T_cur >= self.T_i:\n",
    "                self.cycle += 1\n",
    "                self.T_cur = self.T_cur - self.T_i\n",
    "                self.T_i = (self.T_i - self.T_up) * self.T_mult + self.T_up\n",
    "        else:\n",
    "            if epoch >= self.T_0:\n",
    "                if self.T_mult == 1:\n",
    "                    self.T_cur = epoch % self.T_0\n",
    "                    self.cycle = epoch // self.T_0\n",
    "                else:\n",
    "                    n = int(math.log((epoch / self.T_0 * (self.T_mult - 1) + 1), self.T_mult))\n",
    "                    self.cycle = n\n",
    "                    self.T_cur = epoch - self.T_0 * (self.T_mult ** n - 1) / (self.T_mult - 1)\n",
    "                    self.T_i = self.T_0 * self.T_mult ** (n)\n",
    "            else:\n",
    "                self.T_i = self.T_0\n",
    "                self.T_cur = epoch\n",
    "                \n",
    "        self.eta_max = self.base_eta_max * (self.gamma**self.cycle)\n",
    "        if self.eta_max < self.T_hold:\n",
    "            self.eta_max = self.T_hold\n",
    "        self.last_epoch = math.floor(epoch)\n",
    "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
    "            param_group['lr'] = lr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:19.259300900Z",
     "start_time": "2023-12-26T23:23:19.236282700Z"
    }
   },
   "id": "66827c3c4d6466cd"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id='20231227082319'\n"
     ]
    }
   ],
   "source": [
    "time_now = datetime.now()\n",
    "run_id = time_now.strftime(\"%Y%m%d%H%M%S\")\n",
    "os.makedirs(os.path.join(data_path, f'./runs/{run_id}'), exist_ok=True)\n",
    "print(f'{run_id=}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:19.292637Z",
     "start_time": "2023-12-26T23:23:19.245275600Z"
    }
   },
   "id": "17fc703a3126967"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:19.336050300Z",
     "start_time": "2023-12-26T23:23:19.263302500Z"
    }
   },
   "id": "18993a2b09eac846"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def train(epoch, model, optimizer, criterion, train_loader, device, beta=1, cutmix_prob=0.5, lr_scheduler=None):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    lr_list = []\n",
    "\n",
    "    for idx, (img, label) in enumerate(train_loader):\n",
    "        img, label = img.float().to(device), label.long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        r = np.random.rand(1)\n",
    "        if beta > 0 and r < cutmix_prob:\n",
    "            lam = np.random.beta(beta, beta)\n",
    "            if lam < 0.5:\n",
    "                lam = lam/2 # 0~0.25\n",
    "            else:\n",
    "                lam = 0.5 + lam/2 # 0.75~1\n",
    "            rand_index = torch.randperm(img.size()[0]).cuda()\n",
    "            target_a = label\n",
    "            target_b = label[rand_index]\n",
    "            bbx1, bby1, bbx2, bby2 = rand_bbox(img.size(), lam)\n",
    "            img[:, :, bbx1:bbx2, bby1:bby2] = img[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "\n",
    "            lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (img.size()[-1] * img.size()[-2]))\n",
    "\n",
    "            model_pred = model(img)\n",
    "            loss = criterion(model_pred, target_a) * lam + criterion(model_pred, target_b) * (1. - lam)\n",
    "        else:\n",
    "            model_pred = model(img)\n",
    "            loss = criterion(model_pred, label)\n",
    "\n",
    "        loss.backward()\n",
    "        if ((epoch-1)*len(train_loader) + idx)%10 == 0:\n",
    "            lr_list.append(optimizer.param_groups[0]['lr'])\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "        if lr_scheduler:\n",
    "            lr_scheduler.step()\n",
    "    return np.mean(train_loss), lr_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:19.351219700Z",
     "start_time": "2023-12-26T23:23:19.282639400Z"
    }
   },
   "id": "8837f76bd55e594f"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def competition_metric(true, pred):\n",
    "    return f1_score(true, pred, average=\"macro\")\n",
    "\n",
    "def validation(model, criterion, test_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    model_preds = []\n",
    "    true_labels = []\n",
    "\n",
    "    val_loss = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, label in iter(test_loader):\n",
    "            img, label = img.float().to(device), label.long().to(device)\n",
    "\n",
    "            model_pred = model(img)\n",
    "\n",
    "            loss = criterion(model_pred, label)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            model_preds += model_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += label.detach().cpu().numpy().tolist()\n",
    "\n",
    "    val_f1 = competition_metric(true_labels, model_preds)\n",
    "    return np.mean(val_loss), val_f1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:19.354220900Z",
     "start_time": "2023-12-26T23:23:19.295085400Z"
    }
   },
   "id": "6e0713601b2fa53a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def train_epoch(k, model, optimizer, train_loader, test_loader, lr_scheduler, device):\n",
    "    model.to(device)\n",
    "\n",
    "    criterion = FocalLoss(alpha=1, gamma=2).to(device)\n",
    "    early_stopping = EarlyStopping(patience=CFG['PATIENCE'], verbose=True)\n",
    "\n",
    "    best_score = 0\n",
    "    lr_list = []\n",
    "    train_loss_list, val_loss_list = [], []\n",
    "\n",
    "    for epoch in range(1,CFG[\"EPOCHS\"]+1):\n",
    "        tr_loss, lr_ = train(epoch, model, optimizer, criterion, train_loader, device, beta=1, lr_scheduler=lr_scheduler)\n",
    "        val_loss, val_score = validation(model, criterion, test_loader, device)\n",
    "        train_loss_list.append(tr_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_list.extend(lr_)\n",
    "\n",
    "        if best_score < val_score:\n",
    "            print(f'**Epoch [{k}-{epoch}], lr : [{lr_[-1]:.6f}], Train Loss : [{tr_loss:.4f}], Val Loss : [{val_loss:.4f}], Val F1 Score : [{val_score:.4f}]')\n",
    "            best_score = val_score\n",
    "            torch.save(model, os.path.join(data_path, f'runs/{run_id}/best_model_{k}.pt'))\n",
    "        else:\n",
    "            print(f'Epoch [{k}-{epoch}], lr : [{lr_[-1]:.6f}], Train Loss : [{tr_loss:.4f}], Val Loss : [{val_loss:.4f}], Val F1 Score : [{val_score:.4f}]')\n",
    "        clear_mem()\n",
    "        if early_stopping(val_score):\n",
    "            print(f'Epoch [{k}-{epoch}], early stopping')\n",
    "            break\n",
    "    if lr_list:\n",
    "        return (train_loss_list, val_loss_list, best_score, lr_list)\n",
    "    else:\n",
    "        return (train_loss_list, val_loss_list, best_score, None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:19.355211700Z",
     "start_time": "2023-12-26T23:23:19.312044500Z"
    }
   },
   "id": "533c937dd1370a10"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def k_fold(k): # k-fold\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=False)\n",
    "    f1_sum = 0\n",
    "    \n",
    "    for k_, (train_index, valid_index) in enumerate(skf.split(df, df['artist'])):\n",
    "        print(f'{k_}-fold start')\n",
    "        \n",
    "        # class_counts = df.loc[train_index, 'artist'].value_counts(sort=False).to_dict()\n",
    "        # num_samples = sum(class_counts.values())\n",
    "        # labels = df.loc[train_index, 'artist'].to_list()\n",
    "        # class_weights = {l:round(num_samples/(class_counts[l]**0.5), 2) for l in class_counts.keys()}\n",
    "        # weights = [class_weights[labels[i]] for i in range(int(num_samples))]\n",
    "        # sampler = torch.utils.data.WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "        \n",
    "        train_img_paths, train_labels = get_data(df.iloc[train_index])\n",
    "        val_img_paths, val_labels = get_data(df.iloc[valid_index])\n",
    "        train_dataset = CustomDataset(train_img_paths, train_labels, train_transform)\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, #sampler=sampler,\n",
    "            worker_init_fn=seed_worker, generator=g, num_workers=0\n",
    "        )\n",
    "        \n",
    "        val_dataset = CustomDataset(val_img_paths, val_labels, validation_transform)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, worker_init_fn=seed_worker, generator=g, num_workers=0)\n",
    "        \n",
    "        model = EfficientNetModel()\n",
    "        model.eval()\n",
    "        optimizer = torch.optim.AdamW(params = model.parameters(), lr = CFG['LEARNING_RATE'])\n",
    "        # lr : 5epochs 동안 0.001->CFG['LEARNING_RATE']\n",
    "        lr_scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=CFG['WARMUP']*len(train_loader), T_mult=1, eta_max=0.001, T_up=50, gamma=0.5, T_hold=CFG['LEARNING_RATE']*10)\n",
    "        _, _, f1_score, _ = train_epoch(k_, model, optimizer, train_loader, val_loader, lr_scheduler, device)\n",
    "        f1_sum += f1_score\n",
    "    return f1_sum/k"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-26T23:23:19.368298600Z",
     "start_time": "2023-12-26T23:23:19.326053300Z"
    }
   },
   "id": "ae68c00c95b41224"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-fold start\n",
      "**Epoch [0-1], lr : [0.000953], Train Loss : [2.4740], Val Loss : [1.5937], Val F1 Score : [0.3331]\n",
      "**Epoch [0-2], lr : [0.000779], Train Loss : [1.7501], Val Loss : [1.0950], Val F1 Score : [0.4930]\n",
      "**Epoch [0-3], lr : [0.000533], Train Loss : [1.4313], Val Loss : [0.8693], Val F1 Score : [0.5714]\n",
      "**Epoch [0-4], lr : [0.000271], Train Loss : [1.1688], Val Loss : [0.6619], Val F1 Score : [0.6673]\n",
      "**Epoch [0-5], lr : [0.000081], Train Loss : [0.9664], Val Loss : [0.6299], Val F1 Score : [0.6948]\n",
      "Epoch [0-6], lr : [0.000006], Train Loss : [0.8606], Val Loss : [0.6037], Val F1 Score : [0.6902]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.6948340641599579\n",
      "Epoch [0-7], lr : [0.000476], Train Loss : [1.0499], Val Loss : [0.8382], Val F1 Score : [0.5952]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.6948340641599579\n",
      "Epoch [0-8], lr : [0.000392], Train Loss : [1.0309], Val Loss : [0.6928], Val F1 Score : [0.6750]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.6948340641599579\n",
      "**Epoch [0-9], lr : [0.000266], Train Loss : [0.8928], Val Loss : [0.5301], Val F1 Score : [0.7154]\n",
      "**Epoch [0-10], lr : [0.000140], Train Loss : [0.7667], Val Loss : [0.5245], Val F1 Score : [0.7299]\n",
      "**Epoch [0-11], lr : [0.000042], Train Loss : [0.6805], Val Loss : [0.4944], Val F1 Score : [0.7357]\n",
      "Epoch [0-12], lr : [0.000006], Train Loss : [0.6628], Val Loss : [0.5452], Val F1 Score : [0.7268]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7357438387996632\n",
      "Epoch [0-13], lr : [0.000239], Train Loss : [0.6537], Val Loss : [0.5154], Val F1 Score : [0.7278]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7357438387996632\n",
      "**Epoch [0-14], lr : [0.000196], Train Loss : [0.6872], Val Loss : [0.4962], Val F1 Score : [0.7405]\n",
      "Epoch [0-15], lr : [0.000136], Train Loss : [0.6276], Val Loss : [0.5071], Val F1 Score : [0.7297]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7405198001331827\n",
      "**Epoch [0-16], lr : [0.000071], Train Loss : [0.6272], Val Loss : [0.4596], Val F1 Score : [0.7629]\n",
      "Epoch [0-17], lr : [0.000024], Train Loss : [0.5993], Val Loss : [0.4508], Val F1 Score : [0.7603]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7629439189189681\n",
      "**Epoch [0-18], lr : [0.000006], Train Loss : [0.5406], Val Loss : [0.4607], Val F1 Score : [0.7670]\n",
      "Epoch [0-19], lr : [0.000119], Train Loss : [0.5540], Val Loss : [0.4880], Val F1 Score : [0.7614]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7669886775410382\n",
      "**Epoch [0-20], lr : [0.000099], Train Loss : [0.5242], Val Loss : [0.4584], Val F1 Score : [0.7767]\n",
      "Epoch [0-21], lr : [0.000069], Train Loss : [0.5487], Val Loss : [0.4655], Val F1 Score : [0.7704]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7766987824096252\n",
      "**Epoch [0-22], lr : [0.000038], Train Loss : [0.5356], Val Loss : [0.4372], Val F1 Score : [0.7900]\n",
      "Epoch [0-23], lr : [0.000015], Train Loss : [0.4659], Val Loss : [0.4188], Val F1 Score : [0.7712]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7900393098794926\n",
      "Epoch [0-24], lr : [0.000006], Train Loss : [0.5046], Val Loss : [0.4382], Val F1 Score : [0.7781]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7900393098794926\n",
      "Epoch [0-25], lr : [0.000060], Train Loss : [0.5413], Val Loss : [0.4525], Val F1 Score : [0.7716]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.7900393098794926\n",
      "Epoch [0-26], lr : [0.000050], Train Loss : [0.4037], Val Loss : [0.4354], Val F1 Score : [0.7860]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.7900393098794926\n",
      "Epoch [0-27], lr : [0.000036], Train Loss : [0.4928], Val Loss : [0.4440], Val F1 Score : [0.7854]\n",
      "EarlyStopping counter: 5 out of 12\n",
      "Best F1 score from now: 0.7900393098794926\n",
      "Epoch [0-28], lr : [0.000021], Train Loss : [0.4795], Val Loss : [0.4382], Val F1 Score : [0.7815]\n",
      "EarlyStopping counter: 6 out of 12\n",
      "Best F1 score from now: 0.7900393098794926\n",
      "**Epoch [0-29], lr : [0.000010], Train Loss : [0.4773], Val Loss : [0.4205], Val F1 Score : [0.7970]\n",
      "Epoch [0-30], lr : [0.000006], Train Loss : [0.4696], Val Loss : [0.4360], Val F1 Score : [0.7771]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7970068413198516\n",
      "Epoch [0-31], lr : [0.000057], Train Loss : [0.4529], Val Loss : [0.4463], Val F1 Score : [0.7489]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7970068413198516\n",
      "Epoch [0-32], lr : [0.000048], Train Loss : [0.4721], Val Loss : [0.4614], Val F1 Score : [0.7677]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.7970068413198516\n",
      "Epoch [0-33], lr : [0.000035], Train Loss : [0.4729], Val Loss : [0.4575], Val F1 Score : [0.7889]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.7970068413198516\n",
      "**Epoch [0-34], lr : [0.000020], Train Loss : [0.4101], Val Loss : [0.4175], Val F1 Score : [0.8028]\n",
      "Epoch [0-35], lr : [0.000010], Train Loss : [0.4440], Val Loss : [0.4055], Val F1 Score : [0.7863]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.8028040978897931\n",
      "Epoch [0-36], lr : [0.000006], Train Loss : [0.4419], Val Loss : [0.4558], Val F1 Score : [0.7769]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.8028040978897931\n",
      "Epoch [0-37], lr : [0.000057], Train Loss : [0.4590], Val Loss : [0.4477], Val F1 Score : [0.7693]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.8028040978897931\n",
      "Epoch [0-38], lr : [0.000048], Train Loss : [0.4232], Val Loss : [0.4585], Val F1 Score : [0.7898]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.8028040978897931\n",
      "Epoch [0-39], lr : [0.000034], Train Loss : [0.4879], Val Loss : [0.4472], Val F1 Score : [0.7783]\n",
      "EarlyStopping counter: 5 out of 12\n",
      "Best F1 score from now: 0.8028040978897931\n",
      "Epoch [0-40], lr : [0.000021], Train Loss : [0.4966], Val Loss : [0.4469], Val F1 Score : [0.7956]\n",
      "EarlyStopping counter: 6 out of 12\n",
      "Best F1 score from now: 0.8028040978897931\n",
      "Epoch [0-41], lr : [0.000010], Train Loss : [0.4184], Val Loss : [0.4101], Val F1 Score : [0.7890]\n",
      "EarlyStopping counter: 7 out of 12\n",
      "Best F1 score from now: 0.8028040978897931\n",
      "Epoch [0-42], lr : [0.000006], Train Loss : [0.4275], Val Loss : [0.4024], Val F1 Score : [0.7768]\n",
      "EarlyStopping counter: 8 out of 12\n",
      "Best F1 score from now: 0.8028040978897931\n",
      "Epoch [0-43], lr : [0.000058], Train Loss : [0.3916], Val Loss : [0.4193], Val F1 Score : [0.7975]\n",
      "EarlyStopping counter: 9 out of 12\n",
      "Best F1 score from now: 0.8028040978897931\n",
      "Epoch [0-44], lr : [0.000048], Train Loss : [0.4589], Val Loss : [0.4366], Val F1 Score : [0.7732]\n",
      "EarlyStopping counter: 10 out of 12\n",
      "Best F1 score from now: 0.8028040978897931\n",
      "**Epoch [0-45], lr : [0.000035], Train Loss : [0.4433], Val Loss : [0.4063], Val F1 Score : [0.8048]\n",
      "Epoch [0-46], lr : [0.000020], Train Loss : [0.4084], Val Loss : [0.4093], Val F1 Score : [0.7988]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.804757274635183\n",
      "**Epoch [0-47], lr : [0.000010], Train Loss : [0.4373], Val Loss : [0.3877], Val F1 Score : [0.8103]\n",
      "Epoch [0-48], lr : [0.000006], Train Loss : [0.3872], Val Loss : [0.4152], Val F1 Score : [0.7960]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.810331932217657\n",
      "Epoch [0-49], lr : [0.000057], Train Loss : [0.4112], Val Loss : [0.4448], Val F1 Score : [0.7788]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.810331932217657\n",
      "Epoch [0-50], lr : [0.000048], Train Loss : [0.4260], Val Loss : [0.3976], Val F1 Score : [0.7921]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.810331932217657\n",
      "Epoch [0-51], lr : [0.000035], Train Loss : [0.3567], Val Loss : [0.4436], Val F1 Score : [0.7739]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.810331932217657\n",
      "Epoch [0-52], lr : [0.000020], Train Loss : [0.3747], Val Loss : [0.4166], Val F1 Score : [0.7844]\n",
      "EarlyStopping counter: 5 out of 12\n",
      "Best F1 score from now: 0.810331932217657\n",
      "Epoch [0-53], lr : [0.000010], Train Loss : [0.4039], Val Loss : [0.4288], Val F1 Score : [0.7868]\n",
      "EarlyStopping counter: 6 out of 12\n",
      "Best F1 score from now: 0.810331932217657\n",
      "Epoch [0-54], lr : [0.000006], Train Loss : [0.3833], Val Loss : [0.4087], Val F1 Score : [0.7888]\n",
      "EarlyStopping counter: 7 out of 12\n",
      "Best F1 score from now: 0.810331932217657\n",
      "Epoch [0-55], lr : [0.000058], Train Loss : [0.3695], Val Loss : [0.4312], Val F1 Score : [0.7891]\n",
      "EarlyStopping counter: 8 out of 12\n",
      "Best F1 score from now: 0.810331932217657\n",
      "Epoch [0-56], lr : [0.000048], Train Loss : [0.3728], Val Loss : [0.4261], Val F1 Score : [0.7806]\n",
      "EarlyStopping counter: 9 out of 12\n",
      "Best F1 score from now: 0.810331932217657\n",
      "Epoch [0-57], lr : [0.000034], Train Loss : [0.4234], Val Loss : [0.4101], Val F1 Score : [0.7947]\n",
      "EarlyStopping counter: 10 out of 12\n",
      "Best F1 score from now: 0.810331932217657\n",
      "Epoch [0-58], lr : [0.000021], Train Loss : [0.3651], Val Loss : [0.4293], Val F1 Score : [0.7847]\n",
      "EarlyStopping counter: 11 out of 12\n",
      "Best F1 score from now: 0.810331932217657\n",
      "Epoch [0-59], lr : [0.000010], Train Loss : [0.3963], Val Loss : [0.4391], Val F1 Score : [0.7926]\n",
      "EarlyStopping counter: 12 out of 12\n",
      "Best F1 score from now: 0.810331932217657\n",
      "Epoch [0-59], early stopping\n",
      "1-fold start\n",
      "**Epoch [1-1], lr : [0.000953], Train Loss : [2.4702], Val Loss : [1.4166], Val F1 Score : [0.3342]\n",
      "**Epoch [1-2], lr : [0.000779], Train Loss : [1.7546], Val Loss : [1.0645], Val F1 Score : [0.4748]\n",
      "**Epoch [1-3], lr : [0.000533], Train Loss : [1.4081], Val Loss : [0.8775], Val F1 Score : [0.5578]\n",
      "**Epoch [1-4], lr : [0.000271], Train Loss : [1.1464], Val Loss : [0.6798], Val F1 Score : [0.6605]\n",
      "**Epoch [1-5], lr : [0.000081], Train Loss : [0.9662], Val Loss : [0.5669], Val F1 Score : [0.7039]\n",
      "**Epoch [1-6], lr : [0.000006], Train Loss : [0.8514], Val Loss : [0.5514], Val F1 Score : [0.7137]\n",
      "Epoch [1-7], lr : [0.000476], Train Loss : [1.0543], Val Loss : [0.6910], Val F1 Score : [0.6594]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7136900743611397\n",
      "Epoch [1-8], lr : [0.000392], Train Loss : [1.0786], Val Loss : [0.6665], Val F1 Score : [0.6896]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7136900743611397\n",
      "**Epoch [1-9], lr : [0.000266], Train Loss : [0.9341], Val Loss : [0.5356], Val F1 Score : [0.7253]\n",
      "**Epoch [1-10], lr : [0.000140], Train Loss : [0.7616], Val Loss : [0.4616], Val F1 Score : [0.7322]\n",
      "**Epoch [1-11], lr : [0.000042], Train Loss : [0.6737], Val Loss : [0.4416], Val F1 Score : [0.7627]\n",
      "Epoch [1-12], lr : [0.000006], Train Loss : [0.6332], Val Loss : [0.4562], Val F1 Score : [0.7449]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7626555574999274\n",
      "Epoch [1-13], lr : [0.000239], Train Loss : [0.6815], Val Loss : [0.5716], Val F1 Score : [0.7061]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7626555574999274\n",
      "Epoch [1-14], lr : [0.000196], Train Loss : [0.6918], Val Loss : [0.4838], Val F1 Score : [0.7366]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.7626555574999274\n",
      "**Epoch [1-15], lr : [0.000136], Train Loss : [0.6492], Val Loss : [0.4397], Val F1 Score : [0.7628]\n",
      "**Epoch [1-16], lr : [0.000071], Train Loss : [0.5495], Val Loss : [0.4412], Val F1 Score : [0.7715]\n",
      "Epoch [1-17], lr : [0.000024], Train Loss : [0.5359], Val Loss : [0.4253], Val F1 Score : [0.7662]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7715005506353545\n",
      "**Epoch [1-18], lr : [0.000006], Train Loss : [0.4773], Val Loss : [0.4107], Val F1 Score : [0.7805]\n",
      "Epoch [1-19], lr : [0.000119], Train Loss : [0.5419], Val Loss : [0.4135], Val F1 Score : [0.7599]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.780494051390558\n",
      "**Epoch [1-20], lr : [0.000099], Train Loss : [0.5592], Val Loss : [0.4179], Val F1 Score : [0.7823]\n",
      "Epoch [1-21], lr : [0.000069], Train Loss : [0.5308], Val Loss : [0.4135], Val F1 Score : [0.7763]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7823055380411847\n",
      "**Epoch [1-22], lr : [0.000038], Train Loss : [0.5089], Val Loss : [0.4140], Val F1 Score : [0.7918]\n",
      "Epoch [1-23], lr : [0.000015], Train Loss : [0.4840], Val Loss : [0.4106], Val F1 Score : [0.7819]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7918170891772344\n",
      "**Epoch [1-24], lr : [0.000006], Train Loss : [0.4339], Val Loss : [0.4012], Val F1 Score : [0.7951]\n",
      "Epoch [1-25], lr : [0.000060], Train Loss : [0.4874], Val Loss : [0.4258], Val F1 Score : [0.7793]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7951390019344562\n",
      "Epoch [1-26], lr : [0.000050], Train Loss : [0.5131], Val Loss : [0.3950], Val F1 Score : [0.7941]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7951390019344562\n",
      "**Epoch [1-27], lr : [0.000036], Train Loss : [0.4391], Val Loss : [0.4042], Val F1 Score : [0.8085]\n",
      "Epoch [1-28], lr : [0.000021], Train Loss : [0.4652], Val Loss : [0.3806], Val F1 Score : [0.7897]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.8085044735557948\n",
      "Epoch [1-29], lr : [0.000010], Train Loss : [0.4462], Val Loss : [0.3858], Val F1 Score : [0.7934]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.8085044735557948\n",
      "Epoch [1-30], lr : [0.000006], Train Loss : [0.4315], Val Loss : [0.3693], Val F1 Score : [0.8077]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.8085044735557948\n",
      "Epoch [1-31], lr : [0.000057], Train Loss : [0.4257], Val Loss : [0.3800], Val F1 Score : [0.7984]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.8085044735557948\n",
      "Epoch [1-32], lr : [0.000048], Train Loss : [0.4286], Val Loss : [0.3830], Val F1 Score : [0.7974]\n",
      "EarlyStopping counter: 5 out of 12\n",
      "Best F1 score from now: 0.8085044735557948\n",
      "Epoch [1-33], lr : [0.000035], Train Loss : [0.4239], Val Loss : [0.3739], Val F1 Score : [0.7990]\n",
      "EarlyStopping counter: 6 out of 12\n",
      "Best F1 score from now: 0.8085044735557948\n",
      "Epoch [1-34], lr : [0.000020], Train Loss : [0.4559], Val Loss : [0.3758], Val F1 Score : [0.8065]\n",
      "EarlyStopping counter: 7 out of 12\n",
      "Best F1 score from now: 0.8085044735557948\n",
      "Epoch [1-35], lr : [0.000010], Train Loss : [0.4002], Val Loss : [0.3880], Val F1 Score : [0.7939]\n",
      "EarlyStopping counter: 8 out of 12\n",
      "Best F1 score from now: 0.8085044735557948\n",
      "Epoch [1-36], lr : [0.000006], Train Loss : [0.4269], Val Loss : [0.3863], Val F1 Score : [0.7812]\n",
      "EarlyStopping counter: 9 out of 12\n",
      "Best F1 score from now: 0.8085044735557948\n",
      "Epoch [1-37], lr : [0.000057], Train Loss : [0.3972], Val Loss : [0.4045], Val F1 Score : [0.7762]\n",
      "EarlyStopping counter: 10 out of 12\n",
      "Best F1 score from now: 0.8085044735557948\n",
      "**Epoch [1-38], lr : [0.000048], Train Loss : [0.4326], Val Loss : [0.3643], Val F1 Score : [0.8096]\n",
      "**Epoch [1-39], lr : [0.000034], Train Loss : [0.4107], Val Loss : [0.3935], Val F1 Score : [0.8111]\n",
      "Epoch [1-40], lr : [0.000021], Train Loss : [0.3967], Val Loss : [0.3626], Val F1 Score : [0.8035]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.8111099518424922\n",
      "Epoch [1-41], lr : [0.000010], Train Loss : [0.3357], Val Loss : [0.3942], Val F1 Score : [0.7839]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.8111099518424922\n",
      "Epoch [1-42], lr : [0.000006], Train Loss : [0.3804], Val Loss : [0.3686], Val F1 Score : [0.7899]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.8111099518424922\n",
      "**Epoch [1-43], lr : [0.000058], Train Loss : [0.3590], Val Loss : [0.3707], Val F1 Score : [0.8233]\n",
      "Epoch [1-44], lr : [0.000048], Train Loss : [0.4146], Val Loss : [0.3690], Val F1 Score : [0.8036]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.8232707540895927\n",
      "Epoch [1-45], lr : [0.000035], Train Loss : [0.4278], Val Loss : [0.3707], Val F1 Score : [0.7949]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.8232707540895927\n",
      "Epoch [1-46], lr : [0.000020], Train Loss : [0.4407], Val Loss : [0.4062], Val F1 Score : [0.8029]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.8232707540895927\n",
      "Epoch [1-47], lr : [0.000010], Train Loss : [0.4097], Val Loss : [0.3735], Val F1 Score : [0.8106]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.8232707540895927\n",
      "Epoch [1-48], lr : [0.000006], Train Loss : [0.4173], Val Loss : [0.3637], Val F1 Score : [0.8055]\n",
      "EarlyStopping counter: 5 out of 12\n",
      "Best F1 score from now: 0.8232707540895927\n",
      "Epoch [1-49], lr : [0.000057], Train Loss : [0.3762], Val Loss : [0.3895], Val F1 Score : [0.8104]\n",
      "EarlyStopping counter: 6 out of 12\n",
      "Best F1 score from now: 0.8232707540895927\n",
      "Epoch [1-50], lr : [0.000048], Train Loss : [0.3899], Val Loss : [0.3488], Val F1 Score : [0.8214]\n",
      "EarlyStopping counter: 7 out of 12\n",
      "Best F1 score from now: 0.8232707540895927\n",
      "Epoch [1-51], lr : [0.000035], Train Loss : [0.3897], Val Loss : [0.3665], Val F1 Score : [0.8098]\n",
      "EarlyStopping counter: 8 out of 12\n",
      "Best F1 score from now: 0.8232707540895927\n",
      "Epoch [1-52], lr : [0.000020], Train Loss : [0.3421], Val Loss : [0.3526], Val F1 Score : [0.8104]\n",
      "EarlyStopping counter: 9 out of 12\n",
      "Best F1 score from now: 0.8232707540895927\n",
      "Epoch [1-53], lr : [0.000010], Train Loss : [0.3877], Val Loss : [0.3359], Val F1 Score : [0.8145]\n",
      "EarlyStopping counter: 10 out of 12\n",
      "Best F1 score from now: 0.8232707540895927\n",
      "Epoch [1-54], lr : [0.000006], Train Loss : [0.3632], Val Loss : [0.3448], Val F1 Score : [0.8041]\n",
      "EarlyStopping counter: 11 out of 12\n",
      "Best F1 score from now: 0.8232707540895927\n",
      "Epoch [1-55], lr : [0.000058], Train Loss : [0.3376], Val Loss : [0.3733], Val F1 Score : [0.7893]\n",
      "EarlyStopping counter: 12 out of 12\n",
      "Best F1 score from now: 0.8232707540895927\n",
      "Epoch [1-55], early stopping\n",
      "2-fold start\n",
      "**Epoch [2-1], lr : [0.000953], Train Loss : [2.4126], Val Loss : [1.5046], Val F1 Score : [0.3409]\n",
      "**Epoch [2-2], lr : [0.000779], Train Loss : [1.7514], Val Loss : [1.0820], Val F1 Score : [0.4761]\n",
      "**Epoch [2-3], lr : [0.000533], Train Loss : [1.4273], Val Loss : [0.8457], Val F1 Score : [0.6005]\n",
      "**Epoch [2-4], lr : [0.000271], Train Loss : [1.0790], Val Loss : [0.6372], Val F1 Score : [0.6696]\n",
      "**Epoch [2-5], lr : [0.000081], Train Loss : [0.9444], Val Loss : [0.6099], Val F1 Score : [0.6809]\n",
      "**Epoch [2-6], lr : [0.000006], Train Loss : [0.8315], Val Loss : [0.5757], Val F1 Score : [0.7164]\n",
      "Epoch [2-7], lr : [0.000476], Train Loss : [1.0467], Val Loss : [0.7891], Val F1 Score : [0.6250]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7164365309832513\n",
      "Epoch [2-8], lr : [0.000392], Train Loss : [1.0550], Val Loss : [0.6617], Val F1 Score : [0.6882]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7164365309832513\n",
      "Epoch [2-9], lr : [0.000266], Train Loss : [0.8177], Val Loss : [0.5945], Val F1 Score : [0.6933]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.7164365309832513\n",
      "**Epoch [2-10], lr : [0.000140], Train Loss : [0.7538], Val Loss : [0.5596], Val F1 Score : [0.7229]\n",
      "**Epoch [2-11], lr : [0.000042], Train Loss : [0.6691], Val Loss : [0.4858], Val F1 Score : [0.7593]\n",
      "Epoch [2-12], lr : [0.000006], Train Loss : [0.6314], Val Loss : [0.4846], Val F1 Score : [0.7575]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7592689759648578\n",
      "Epoch [2-13], lr : [0.000239], Train Loss : [0.6503], Val Loss : [0.5458], Val F1 Score : [0.7555]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7592689759648578\n",
      "Epoch [2-14], lr : [0.000196], Train Loss : [0.7000], Val Loss : [0.5366], Val F1 Score : [0.7304]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.7592689759648578\n",
      "**Epoch [2-15], lr : [0.000136], Train Loss : [0.5980], Val Loss : [0.4875], Val F1 Score : [0.7656]\n",
      "**Epoch [2-16], lr : [0.000071], Train Loss : [0.5546], Val Loss : [0.4585], Val F1 Score : [0.7738]\n",
      "**Epoch [2-17], lr : [0.000024], Train Loss : [0.5214], Val Loss : [0.4651], Val F1 Score : [0.7755]\n",
      "Epoch [2-18], lr : [0.000006], Train Loss : [0.5525], Val Loss : [0.4435], Val F1 Score : [0.7736]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7754503554836589\n",
      "Epoch [2-19], lr : [0.000119], Train Loss : [0.5530], Val Loss : [0.4722], Val F1 Score : [0.7675]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7754503554836589\n",
      "Epoch [2-20], lr : [0.000099], Train Loss : [0.5789], Val Loss : [0.4694], Val F1 Score : [0.7693]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.7754503554836589\n",
      "Epoch [2-21], lr : [0.000069], Train Loss : [0.5541], Val Loss : [0.4712], Val F1 Score : [0.7685]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.7754503554836589\n",
      "**Epoch [2-22], lr : [0.000038], Train Loss : [0.4671], Val Loss : [0.4518], Val F1 Score : [0.7837]\n",
      "**Epoch [2-23], lr : [0.000015], Train Loss : [0.4874], Val Loss : [0.4491], Val F1 Score : [0.7864]\n",
      "Epoch [2-24], lr : [0.000006], Train Loss : [0.4797], Val Loss : [0.4351], Val F1 Score : [0.7739]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7863976926531803\n",
      "Epoch [2-25], lr : [0.000060], Train Loss : [0.4889], Val Loss : [0.4581], Val F1 Score : [0.7624]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7863976926531803\n",
      "Epoch [2-26], lr : [0.000050], Train Loss : [0.4894], Val Loss : [0.4438], Val F1 Score : [0.7776]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.7863976926531803\n",
      "Epoch [2-27], lr : [0.000036], Train Loss : [0.4383], Val Loss : [0.4534], Val F1 Score : [0.7654]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.7863976926531803\n",
      "Epoch [2-28], lr : [0.000021], Train Loss : [0.4638], Val Loss : [0.4160], Val F1 Score : [0.7677]\n",
      "EarlyStopping counter: 5 out of 12\n",
      "Best F1 score from now: 0.7863976926531803\n",
      "Epoch [2-29], lr : [0.000010], Train Loss : [0.4577], Val Loss : [0.4571], Val F1 Score : [0.7773]\n",
      "EarlyStopping counter: 6 out of 12\n",
      "Best F1 score from now: 0.7863976926531803\n",
      "**Epoch [2-30], lr : [0.000006], Train Loss : [0.4672], Val Loss : [0.4375], Val F1 Score : [0.7940]\n",
      "Epoch [2-31], lr : [0.000057], Train Loss : [0.4656], Val Loss : [0.4640], Val F1 Score : [0.7867]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7940321705026345\n",
      "Epoch [2-32], lr : [0.000048], Train Loss : [0.4585], Val Loss : [0.4470], Val F1 Score : [0.7744]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7940321705026345\n",
      "Epoch [2-33], lr : [0.000035], Train Loss : [0.3881], Val Loss : [0.4334], Val F1 Score : [0.7764]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.7940321705026345\n",
      "Epoch [2-34], lr : [0.000020], Train Loss : [0.4167], Val Loss : [0.4273], Val F1 Score : [0.7818]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.7940321705026345\n",
      "Epoch [2-35], lr : [0.000010], Train Loss : [0.4531], Val Loss : [0.4337], Val F1 Score : [0.7736]\n",
      "EarlyStopping counter: 5 out of 12\n",
      "Best F1 score from now: 0.7940321705026345\n",
      "Epoch [2-36], lr : [0.000006], Train Loss : [0.3908], Val Loss : [0.4181], Val F1 Score : [0.7935]\n",
      "EarlyStopping counter: 6 out of 12\n",
      "Best F1 score from now: 0.7940321705026345\n",
      "Epoch [2-37], lr : [0.000057], Train Loss : [0.4101], Val Loss : [0.4394], Val F1 Score : [0.7849]\n",
      "EarlyStopping counter: 7 out of 12\n",
      "Best F1 score from now: 0.7940321705026345\n",
      "Epoch [2-38], lr : [0.000048], Train Loss : [0.4547], Val Loss : [0.4183], Val F1 Score : [0.7849]\n",
      "EarlyStopping counter: 8 out of 12\n",
      "Best F1 score from now: 0.7940321705026345\n",
      "Epoch [2-39], lr : [0.000034], Train Loss : [0.4416], Val Loss : [0.4336], Val F1 Score : [0.7874]\n",
      "EarlyStopping counter: 9 out of 12\n",
      "Best F1 score from now: 0.7940321705026345\n",
      "**Epoch [2-40], lr : [0.000021], Train Loss : [0.4095], Val Loss : [0.4078], Val F1 Score : [0.8213]\n",
      "Epoch [2-41], lr : [0.000010], Train Loss : [0.4473], Val Loss : [0.3880], Val F1 Score : [0.8150]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.8212531573655272\n",
      "**Epoch [2-42], lr : [0.000006], Train Loss : [0.4004], Val Loss : [0.4116], Val F1 Score : [0.8271]\n",
      "Epoch [2-43], lr : [0.000058], Train Loss : [0.3990], Val Loss : [0.4315], Val F1 Score : [0.8090]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.8270931638227589\n",
      "Epoch [2-44], lr : [0.000048], Train Loss : [0.4459], Val Loss : [0.4283], Val F1 Score : [0.8090]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.8270931638227589\n",
      "Epoch [2-45], lr : [0.000035], Train Loss : [0.4402], Val Loss : [0.4172], Val F1 Score : [0.7929]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.8270931638227589\n",
      "Epoch [2-46], lr : [0.000020], Train Loss : [0.4047], Val Loss : [0.4158], Val F1 Score : [0.7967]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.8270931638227589\n",
      "Epoch [2-47], lr : [0.000010], Train Loss : [0.3893], Val Loss : [0.4148], Val F1 Score : [0.8048]\n",
      "EarlyStopping counter: 5 out of 12\n",
      "Best F1 score from now: 0.8270931638227589\n",
      "Epoch [2-48], lr : [0.000006], Train Loss : [0.3993], Val Loss : [0.4209], Val F1 Score : [0.7825]\n",
      "EarlyStopping counter: 6 out of 12\n",
      "Best F1 score from now: 0.8270931638227589\n",
      "Epoch [2-49], lr : [0.000057], Train Loss : [0.4000], Val Loss : [0.4284], Val F1 Score : [0.8040]\n",
      "EarlyStopping counter: 7 out of 12\n",
      "Best F1 score from now: 0.8270931638227589\n",
      "Epoch [2-50], lr : [0.000048], Train Loss : [0.3849], Val Loss : [0.4334], Val F1 Score : [0.7859]\n",
      "EarlyStopping counter: 8 out of 12\n",
      "Best F1 score from now: 0.8270931638227589\n",
      "Epoch [2-51], lr : [0.000035], Train Loss : [0.4187], Val Loss : [0.4146], Val F1 Score : [0.7949]\n",
      "EarlyStopping counter: 9 out of 12\n",
      "Best F1 score from now: 0.8270931638227589\n",
      "Epoch [2-52], lr : [0.000020], Train Loss : [0.3918], Val Loss : [0.4230], Val F1 Score : [0.8002]\n",
      "EarlyStopping counter: 10 out of 12\n",
      "Best F1 score from now: 0.8270931638227589\n",
      "Epoch [2-53], lr : [0.000010], Train Loss : [0.3805], Val Loss : [0.4191], Val F1 Score : [0.8006]\n",
      "EarlyStopping counter: 11 out of 12\n",
      "Best F1 score from now: 0.8270931638227589\n",
      "Epoch [2-54], lr : [0.000006], Train Loss : [0.3380], Val Loss : [0.4321], Val F1 Score : [0.7820]\n",
      "EarlyStopping counter: 12 out of 12\n",
      "Best F1 score from now: 0.8270931638227589\n",
      "Epoch [2-54], early stopping\n",
      "3-fold start\n",
      "**Epoch [3-1], lr : [0.000953], Train Loss : [2.4940], Val Loss : [1.6237], Val F1 Score : [0.2999]\n",
      "**Epoch [3-2], lr : [0.000779], Train Loss : [1.8070], Val Loss : [1.1051], Val F1 Score : [0.4693]\n",
      "**Epoch [3-3], lr : [0.000533], Train Loss : [1.5132], Val Loss : [0.8396], Val F1 Score : [0.5981]\n",
      "**Epoch [3-4], lr : [0.000271], Train Loss : [1.1506], Val Loss : [0.7137], Val F1 Score : [0.6491]\n",
      "**Epoch [3-5], lr : [0.000081], Train Loss : [0.9956], Val Loss : [0.6078], Val F1 Score : [0.7128]\n",
      "**Epoch [3-6], lr : [0.000006], Train Loss : [0.8887], Val Loss : [0.5746], Val F1 Score : [0.7170]\n",
      "Epoch [3-7], lr : [0.000476], Train Loss : [1.0417], Val Loss : [0.7431], Val F1 Score : [0.6397]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7170002128698779\n",
      "Epoch [3-8], lr : [0.000392], Train Loss : [0.9971], Val Loss : [0.6348], Val F1 Score : [0.6927]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7170002128698779\n",
      "Epoch [3-9], lr : [0.000266], Train Loss : [0.8502], Val Loss : [0.5936], Val F1 Score : [0.7014]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.7170002128698779\n",
      "**Epoch [3-10], lr : [0.000140], Train Loss : [0.7742], Val Loss : [0.5035], Val F1 Score : [0.7434]\n",
      "**Epoch [3-11], lr : [0.000042], Train Loss : [0.7094], Val Loss : [0.4811], Val F1 Score : [0.7611]\n",
      "Epoch [3-12], lr : [0.000006], Train Loss : [0.6373], Val Loss : [0.5039], Val F1 Score : [0.7520]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7611358931071013\n",
      "Epoch [3-13], lr : [0.000239], Train Loss : [0.7015], Val Loss : [0.5510], Val F1 Score : [0.7251]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7611358931071013\n",
      "**Epoch [3-14], lr : [0.000196], Train Loss : [0.6841], Val Loss : [0.5247], Val F1 Score : [0.7636]\n",
      "**Epoch [3-15], lr : [0.000136], Train Loss : [0.6359], Val Loss : [0.4539], Val F1 Score : [0.7703]\n",
      "**Epoch [3-16], lr : [0.000071], Train Loss : [0.6129], Val Loss : [0.4727], Val F1 Score : [0.7801]\n",
      "Epoch [3-17], lr : [0.000024], Train Loss : [0.5326], Val Loss : [0.4524], Val F1 Score : [0.7800]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7800845990547661\n",
      "**Epoch [3-18], lr : [0.000006], Train Loss : [0.5786], Val Loss : [0.4356], Val F1 Score : [0.7953]\n",
      "Epoch [3-19], lr : [0.000119], Train Loss : [0.6367], Val Loss : [0.5183], Val F1 Score : [0.7489]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7953190004384916\n",
      "Epoch [3-20], lr : [0.000099], Train Loss : [0.5442], Val Loss : [0.4749], Val F1 Score : [0.7717]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7953190004384916\n",
      "Epoch [3-21], lr : [0.000069], Train Loss : [0.5505], Val Loss : [0.4648], Val F1 Score : [0.7771]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.7953190004384916\n",
      "Epoch [3-22], lr : [0.000038], Train Loss : [0.4464], Val Loss : [0.4619], Val F1 Score : [0.7907]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.7953190004384916\n",
      "Epoch [3-23], lr : [0.000015], Train Loss : [0.4929], Val Loss : [0.4555], Val F1 Score : [0.7670]\n",
      "EarlyStopping counter: 5 out of 12\n",
      "Best F1 score from now: 0.7953190004384916\n",
      "Epoch [3-24], lr : [0.000006], Train Loss : [0.5008], Val Loss : [0.4745], Val F1 Score : [0.7690]\n",
      "EarlyStopping counter: 6 out of 12\n",
      "Best F1 score from now: 0.7953190004384916\n",
      "Epoch [3-25], lr : [0.000060], Train Loss : [0.4681], Val Loss : [0.4788], Val F1 Score : [0.7709]\n",
      "EarlyStopping counter: 7 out of 12\n",
      "Best F1 score from now: 0.7953190004384916\n",
      "Epoch [3-26], lr : [0.000050], Train Loss : [0.4804], Val Loss : [0.4611], Val F1 Score : [0.7694]\n",
      "EarlyStopping counter: 8 out of 12\n",
      "Best F1 score from now: 0.7953190004384916\n",
      "Epoch [3-27], lr : [0.000036], Train Loss : [0.4861], Val Loss : [0.4635], Val F1 Score : [0.7865]\n",
      "EarlyStopping counter: 9 out of 12\n",
      "Best F1 score from now: 0.7953190004384916\n",
      "Epoch [3-28], lr : [0.000021], Train Loss : [0.4766], Val Loss : [0.5097], Val F1 Score : [0.7889]\n",
      "EarlyStopping counter: 10 out of 12\n",
      "Best F1 score from now: 0.7953190004384916\n",
      "Epoch [3-29], lr : [0.000010], Train Loss : [0.4394], Val Loss : [0.4561], Val F1 Score : [0.7927]\n",
      "EarlyStopping counter: 11 out of 12\n",
      "Best F1 score from now: 0.7953190004384916\n",
      "Epoch [3-30], lr : [0.000006], Train Loss : [0.4569], Val Loss : [0.5069], Val F1 Score : [0.7717]\n",
      "EarlyStopping counter: 12 out of 12\n",
      "Best F1 score from now: 0.7953190004384916\n",
      "Epoch [3-30], early stopping\n",
      "4-fold start\n",
      "**Epoch [4-1], lr : [0.000953], Train Loss : [2.4360], Val Loss : [1.5837], Val F1 Score : [0.3086]\n",
      "**Epoch [4-2], lr : [0.000779], Train Loss : [1.6980], Val Loss : [1.1283], Val F1 Score : [0.4660]\n",
      "**Epoch [4-3], lr : [0.000533], Train Loss : [1.4003], Val Loss : [0.9245], Val F1 Score : [0.5482]\n",
      "**Epoch [4-4], lr : [0.000271], Train Loss : [1.1719], Val Loss : [0.6862], Val F1 Score : [0.6171]\n",
      "**Epoch [4-5], lr : [0.000081], Train Loss : [0.9623], Val Loss : [0.6107], Val F1 Score : [0.7071]\n",
      "Epoch [4-6], lr : [0.000006], Train Loss : [0.8549], Val Loss : [0.5788], Val F1 Score : [0.7068]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7070790705497225\n",
      "Epoch [4-7], lr : [0.000476], Train Loss : [1.0390], Val Loss : [0.7043], Val F1 Score : [0.6703]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7070790705497225\n",
      "Epoch [4-8], lr : [0.000392], Train Loss : [0.9319], Val Loss : [0.6498], Val F1 Score : [0.6700]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.7070790705497225\n",
      "Epoch [4-9], lr : [0.000266], Train Loss : [0.8613], Val Loss : [0.6307], Val F1 Score : [0.6921]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.7070790705497225\n",
      "**Epoch [4-10], lr : [0.000140], Train Loss : [0.7452], Val Loss : [0.5163], Val F1 Score : [0.7546]\n",
      "Epoch [4-11], lr : [0.000042], Train Loss : [0.6196], Val Loss : [0.5051], Val F1 Score : [0.7506]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7545815184014637\n",
      "Epoch [4-12], lr : [0.000006], Train Loss : [0.5756], Val Loss : [0.5004], Val F1 Score : [0.7523]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7545815184014637\n",
      "Epoch [4-13], lr : [0.000239], Train Loss : [0.7247], Val Loss : [0.5484], Val F1 Score : [0.7495]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.7545815184014637\n",
      "Epoch [4-14], lr : [0.000196], Train Loss : [0.6582], Val Loss : [0.5398], Val F1 Score : [0.7420]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.7545815184014637\n",
      "Epoch [4-15], lr : [0.000136], Train Loss : [0.6709], Val Loss : [0.5166], Val F1 Score : [0.7510]\n",
      "EarlyStopping counter: 5 out of 12\n",
      "Best F1 score from now: 0.7545815184014637\n",
      "**Epoch [4-16], lr : [0.000071], Train Loss : [0.6181], Val Loss : [0.4965], Val F1 Score : [0.7689]\n",
      "**Epoch [4-17], lr : [0.000024], Train Loss : [0.5813], Val Loss : [0.4876], Val F1 Score : [0.7823]\n",
      "Epoch [4-18], lr : [0.000006], Train Loss : [0.5293], Val Loss : [0.4551], Val F1 Score : [0.7688]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7822561863138867\n",
      "Epoch [4-19], lr : [0.000119], Train Loss : [0.5407], Val Loss : [0.5256], Val F1 Score : [0.7627]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.7822561863138867\n",
      "**Epoch [4-20], lr : [0.000099], Train Loss : [0.5334], Val Loss : [0.4807], Val F1 Score : [0.7825]\n",
      "**Epoch [4-21], lr : [0.000069], Train Loss : [0.4855], Val Loss : [0.4626], Val F1 Score : [0.7840]\n",
      "Epoch [4-22], lr : [0.000038], Train Loss : [0.5116], Val Loss : [0.4656], Val F1 Score : [0.7776]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.7839885918526212\n",
      "**Epoch [4-23], lr : [0.000015], Train Loss : [0.5521], Val Loss : [0.4614], Val F1 Score : [0.8029]\n",
      "Epoch [4-24], lr : [0.000006], Train Loss : [0.4542], Val Loss : [0.4757], Val F1 Score : [0.7739]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.8028556978334265\n",
      "Epoch [4-25], lr : [0.000060], Train Loss : [0.4711], Val Loss : [0.4456], Val F1 Score : [0.7986]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.8028556978334265\n",
      "Epoch [4-26], lr : [0.000050], Train Loss : [0.4516], Val Loss : [0.4707], Val F1 Score : [0.7780]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.8028556978334265\n",
      "Epoch [4-27], lr : [0.000036], Train Loss : [0.4961], Val Loss : [0.4545], Val F1 Score : [0.7697]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.8028556978334265\n",
      "Epoch [4-28], lr : [0.000021], Train Loss : [0.4276], Val Loss : [0.4302], Val F1 Score : [0.7866]\n",
      "EarlyStopping counter: 5 out of 12\n",
      "Best F1 score from now: 0.8028556978334265\n",
      "Epoch [4-29], lr : [0.000010], Train Loss : [0.4459], Val Loss : [0.4382], Val F1 Score : [0.7985]\n",
      "EarlyStopping counter: 6 out of 12\n",
      "Best F1 score from now: 0.8028556978334265\n",
      "Epoch [4-30], lr : [0.000006], Train Loss : [0.4103], Val Loss : [0.4389], Val F1 Score : [0.7800]\n",
      "EarlyStopping counter: 7 out of 12\n",
      "Best F1 score from now: 0.8028556978334265\n",
      "Epoch [4-31], lr : [0.000057], Train Loss : [0.4764], Val Loss : [0.4404], Val F1 Score : [0.7937]\n",
      "EarlyStopping counter: 8 out of 12\n",
      "Best F1 score from now: 0.8028556978334265\n",
      "Epoch [4-32], lr : [0.000048], Train Loss : [0.4848], Val Loss : [0.4410], Val F1 Score : [0.7898]\n",
      "EarlyStopping counter: 9 out of 12\n",
      "Best F1 score from now: 0.8028556978334265\n",
      "Epoch [4-33], lr : [0.000035], Train Loss : [0.4398], Val Loss : [0.4362], Val F1 Score : [0.7972]\n",
      "EarlyStopping counter: 10 out of 12\n",
      "Best F1 score from now: 0.8028556978334265\n",
      "**Epoch [4-34], lr : [0.000020], Train Loss : [0.4358], Val Loss : [0.4252], Val F1 Score : [0.8072]\n",
      "Epoch [4-35], lr : [0.000010], Train Loss : [0.3962], Val Loss : [0.4460], Val F1 Score : [0.7861]\n",
      "EarlyStopping counter: 1 out of 12\n",
      "Best F1 score from now: 0.8071510387391055\n",
      "Epoch [4-36], lr : [0.000006], Train Loss : [0.4332], Val Loss : [0.4291], Val F1 Score : [0.8029]\n",
      "EarlyStopping counter: 2 out of 12\n",
      "Best F1 score from now: 0.8071510387391055\n",
      "Epoch [4-37], lr : [0.000057], Train Loss : [0.4260], Val Loss : [0.4638], Val F1 Score : [0.7967]\n",
      "EarlyStopping counter: 3 out of 12\n",
      "Best F1 score from now: 0.8071510387391055\n",
      "Epoch [4-38], lr : [0.000048], Train Loss : [0.4201], Val Loss : [0.4375], Val F1 Score : [0.7846]\n",
      "EarlyStopping counter: 4 out of 12\n",
      "Best F1 score from now: 0.8071510387391055\n",
      "Epoch [4-39], lr : [0.000034], Train Loss : [0.4828], Val Loss : [0.4678], Val F1 Score : [0.7941]\n",
      "EarlyStopping counter: 5 out of 12\n",
      "Best F1 score from now: 0.8071510387391055\n",
      "Epoch [4-40], lr : [0.000021], Train Loss : [0.3731], Val Loss : [0.4732], Val F1 Score : [0.7891]\n",
      "EarlyStopping counter: 6 out of 12\n",
      "Best F1 score from now: 0.8071510387391055\n",
      "Epoch [4-41], lr : [0.000010], Train Loss : [0.4405], Val Loss : [0.4605], Val F1 Score : [0.7943]\n",
      "EarlyStopping counter: 7 out of 12\n",
      "Best F1 score from now: 0.8071510387391055\n",
      "Epoch [4-42], lr : [0.000006], Train Loss : [0.3796], Val Loss : [0.4475], Val F1 Score : [0.8030]\n",
      "EarlyStopping counter: 8 out of 12\n",
      "Best F1 score from now: 0.8071510387391055\n",
      "Epoch [4-43], lr : [0.000058], Train Loss : [0.4208], Val Loss : [0.4416], Val F1 Score : [0.7930]\n",
      "EarlyStopping counter: 9 out of 12\n",
      "Best F1 score from now: 0.8071510387391055\n",
      "Epoch [4-44], lr : [0.000048], Train Loss : [0.4182], Val Loss : [0.4155], Val F1 Score : [0.7975]\n",
      "EarlyStopping counter: 10 out of 12\n",
      "Best F1 score from now: 0.8071510387391055\n",
      "Epoch [4-45], lr : [0.000035], Train Loss : [0.4259], Val Loss : [0.4458], Val F1 Score : [0.7897]\n",
      "EarlyStopping counter: 11 out of 12\n",
      "Best F1 score from now: 0.8071510387391055\n",
      "Epoch [4-46], lr : [0.000020], Train Loss : [0.3901], Val Loss : [0.4696], Val F1 Score : [0.7778]\n",
      "EarlyStopping counter: 12 out of 12\n",
      "Best F1 score from now: 0.8071510387391055\n",
      "Epoch [4-46], early stopping\n",
      "0.8126331778615212\n"
     ]
    }
   ],
   "source": [
    "f1_score = k_fold(CFG['K-FOLD'])\n",
    "print(f1_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T08:01:28.533448700Z",
     "start_time": "2023-12-26T23:23:19.340207900Z"
    }
   },
   "id": "b7ec1f0d6520e962"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "           id               img_path\n0  TEST_00000  ./test/TEST_00000.jpg\n1  TEST_00001  ./test/TEST_00001.jpg\n2  TEST_00002  ./test/TEST_00002.jpg\n3  TEST_00003  ./test/TEST_00003.jpg\n4  TEST_00004  ./test/TEST_00004.jpg",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>img_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TEST_00000</td>\n      <td>./test/TEST_00000.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TEST_00001</td>\n      <td>./test/TEST_00001.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TEST_00002</td>\n      <td>./test/TEST_00002.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TEST_00003</td>\n      <td>./test/TEST_00003.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TEST_00004</td>\n      <td>./test/TEST_00004.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(data_path, './test.csv'))\n",
    "test_df.head()"
   ],
   "metadata": {
    "id": "9c8fff1a450556ec",
    "ExecuteTime": {
     "end_time": "2023-12-27T08:01:28.602875400Z",
     "start_time": "2023-12-27T08:01:28.535567200Z"
    }
   },
   "id": "9c8fff1a450556ec"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "test_img_paths = get_data(test_df, infer=True)"
   ],
   "metadata": {
    "id": "6a50c39d21de27ed",
    "ExecuteTime": {
     "end_time": "2023-12-27T08:01:28.746683800Z",
     "start_time": "2023-12-27T08:01:28.596877400Z"
    }
   },
   "id": "6a50c39d21de27ed"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_img_paths, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ],
   "metadata": {
    "id": "66859c2e35131aae",
    "ExecuteTime": {
     "end_time": "2023-12-27T08:01:28.810360500Z",
     "start_time": "2023-12-27T08:01:28.659166Z"
    }
   },
   "id": "66859c2e35131aae"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    model_preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, img in enumerate(test_loader):\n",
    "            img = img.float().to(device)\n",
    "            \n",
    "            model_pred = model(img).detach().cpu()\n",
    "            model_pred = F.softmax(model_pred, dim=1)\n",
    "            model_preds.extend(model_pred.numpy().tolist())\n",
    "    \n",
    "    print('Done.')\n",
    "    return model_preds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T08:01:28.811359600Z",
     "start_time": "2023-12-27T08:01:28.676601300Z"
    }
   },
   "id": "797a65c3b3a39181"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-fold CHECKPOINT LOADED: ../../data/runs/20231227082319/best_model_0.pt\n",
      "Done.\n",
      "1-fold CHECKPOINT LOADED: ../../data/runs/20231227082319/best_model_1.pt\n",
      "Done.\n",
      "2-fold CHECKPOINT LOADED: ../../data/runs/20231227082319/best_model_2.pt\n",
      "Done.\n",
      "3-fold CHECKPOINT LOADED: ../../data/runs/20231227082319/best_model_3.pt\n",
      "Done.\n",
      "4-fold CHECKPOINT LOADED: ../../data/runs/20231227082319/best_model_4.pt\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.DataFrame(np.zeros((test_df.shape[0], len(le.classes_))))\n",
    "for k_ in range(CFG['K-FOLD']):\n",
    "    checkpoint = os.path.join(data_path, f'runs/{run_id}/best_model_{k_}.pt')\n",
    "    print(f'{k_}-fold CHECKPOINT LOADED: {checkpoint}')\n",
    "    infer_model = torch.load(checkpoint)\n",
    "    ret = inference(infer_model, test_loader, device)\n",
    "    result_df += pd.DataFrame(ret)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T08:09:53.747473100Z",
     "start_time": "2023-12-27T08:01:28.692356800Z"
    }
   },
   "id": "ded4e069ed120f9c"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "         0         1         2         3         4         5         6   \\\n0  0.001397  0.014461  0.006115  0.009963  0.001255  0.003514  0.005037   \n1  0.010086  0.010557  4.299855  0.002922  0.007162  0.002028  0.001507   \n2  0.007688  0.002418  0.001069  0.000760  0.000698  0.000374  3.518337   \n3  4.499340  0.013153  0.005714  0.006060  0.003788  0.003690  0.000345   \n4  0.005345  0.103697  0.766226  0.007619  0.003081  0.032124  0.000546   \n\n         7         8         9   ...        40        41        42        43  \\\n0  0.009877  0.000313  0.029192  ...  0.046525  0.025572  0.074419  0.011467   \n1  0.004107  0.024284  0.007705  ...  0.007607  0.004476  0.006562  0.043186   \n2  0.000591  0.000243  0.080596  ...  0.002441  0.076243  0.019272  0.002810   \n3  0.008508  0.002044  0.001798  ...  0.100425  0.001411  0.004092  0.014246   \n4  0.042435  0.052104  0.004950  ...  0.014405  0.001115  0.004033  0.009710   \n\n         44        45        46        47        48        49  \n0  0.014114  0.046805  0.297027  0.005912  0.990717  0.002871  \n1  0.005298  0.005085  0.012469  0.001932  0.037331  0.004215  \n2  0.076158  0.005674  0.426654  0.000287  0.005591  0.000468  \n3  0.001728  0.003125  0.004640  0.002358  0.139713  0.004749  \n4  0.000993  0.003469  0.008745  0.003246  1.337434  0.001438  \n\n[5 rows x 50 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>40</th>\n      <th>41</th>\n      <th>42</th>\n      <th>43</th>\n      <th>44</th>\n      <th>45</th>\n      <th>46</th>\n      <th>47</th>\n      <th>48</th>\n      <th>49</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001397</td>\n      <td>0.014461</td>\n      <td>0.006115</td>\n      <td>0.009963</td>\n      <td>0.001255</td>\n      <td>0.003514</td>\n      <td>0.005037</td>\n      <td>0.009877</td>\n      <td>0.000313</td>\n      <td>0.029192</td>\n      <td>...</td>\n      <td>0.046525</td>\n      <td>0.025572</td>\n      <td>0.074419</td>\n      <td>0.011467</td>\n      <td>0.014114</td>\n      <td>0.046805</td>\n      <td>0.297027</td>\n      <td>0.005912</td>\n      <td>0.990717</td>\n      <td>0.002871</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.010086</td>\n      <td>0.010557</td>\n      <td>4.299855</td>\n      <td>0.002922</td>\n      <td>0.007162</td>\n      <td>0.002028</td>\n      <td>0.001507</td>\n      <td>0.004107</td>\n      <td>0.024284</td>\n      <td>0.007705</td>\n      <td>...</td>\n      <td>0.007607</td>\n      <td>0.004476</td>\n      <td>0.006562</td>\n      <td>0.043186</td>\n      <td>0.005298</td>\n      <td>0.005085</td>\n      <td>0.012469</td>\n      <td>0.001932</td>\n      <td>0.037331</td>\n      <td>0.004215</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.007688</td>\n      <td>0.002418</td>\n      <td>0.001069</td>\n      <td>0.000760</td>\n      <td>0.000698</td>\n      <td>0.000374</td>\n      <td>3.518337</td>\n      <td>0.000591</td>\n      <td>0.000243</td>\n      <td>0.080596</td>\n      <td>...</td>\n      <td>0.002441</td>\n      <td>0.076243</td>\n      <td>0.019272</td>\n      <td>0.002810</td>\n      <td>0.076158</td>\n      <td>0.005674</td>\n      <td>0.426654</td>\n      <td>0.000287</td>\n      <td>0.005591</td>\n      <td>0.000468</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.499340</td>\n      <td>0.013153</td>\n      <td>0.005714</td>\n      <td>0.006060</td>\n      <td>0.003788</td>\n      <td>0.003690</td>\n      <td>0.000345</td>\n      <td>0.008508</td>\n      <td>0.002044</td>\n      <td>0.001798</td>\n      <td>...</td>\n      <td>0.100425</td>\n      <td>0.001411</td>\n      <td>0.004092</td>\n      <td>0.014246</td>\n      <td>0.001728</td>\n      <td>0.003125</td>\n      <td>0.004640</td>\n      <td>0.002358</td>\n      <td>0.139713</td>\n      <td>0.004749</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.005345</td>\n      <td>0.103697</td>\n      <td>0.766226</td>\n      <td>0.007619</td>\n      <td>0.003081</td>\n      <td>0.032124</td>\n      <td>0.000546</td>\n      <td>0.042435</td>\n      <td>0.052104</td>\n      <td>0.004950</td>\n      <td>...</td>\n      <td>0.014405</td>\n      <td>0.001115</td>\n      <td>0.004033</td>\n      <td>0.009710</td>\n      <td>0.000993</td>\n      <td>0.003469</td>\n      <td>0.008745</td>\n      <td>0.003246</td>\n      <td>1.337434</td>\n      <td>0.001438</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 50 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ],
   "metadata": {
    "id": "9df29cbb4653101f",
    "ExecuteTime": {
     "end_time": "2023-12-27T08:09:53.788672600Z",
     "start_time": "2023-12-27T08:09:53.748473700Z"
    }
   },
   "id": "9df29cbb4653101f"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "preds = result_df.idxmax(axis=1)"
   ],
   "metadata": {
    "id": "37b7f04a0b4de44f",
    "ExecuteTime": {
     "end_time": "2023-12-27T08:09:53.828660700Z",
     "start_time": "2023-12-27T08:09:53.779464900Z"
    }
   },
   "id": "37b7f04a0b4de44f"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "preds = le.inverse_transform(preds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-27T08:09:53.864828600Z",
     "start_time": "2023-12-27T08:09:53.807816600Z"
    }
   },
   "id": "7b9443f3d69be4de"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "submit = pd.read_csv(os.path.join(data_path, './sample_submission.csv'))"
   ],
   "metadata": {
    "id": "fe59292099a9b96e",
    "ExecuteTime": {
     "end_time": "2023-12-27T08:09:53.945112100Z",
     "start_time": "2023-12-27T08:09:53.822119500Z"
    }
   },
   "id": "fe59292099a9b96e"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "submit['artist'] = preds"
   ],
   "metadata": {
    "id": "8582475a6cb3db6f",
    "ExecuteTime": {
     "end_time": "2023-12-27T08:09:53.945112100Z",
     "start_time": "2023-12-27T08:09:53.872830700Z"
    }
   },
   "id": "8582475a6cb3db6f"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "           id             artist\n0  TEST_00000        Edgar Degas\n1  TEST_00001  Amedeo Modigliani\n2  TEST_00002         Caravaggio\n3  TEST_00003    Albrecht Du rer\n4  TEST_00004        Edgar Degas",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>artist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TEST_00000</td>\n      <td>Edgar Degas</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>TEST_00001</td>\n      <td>Amedeo Modigliani</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>TEST_00002</td>\n      <td>Caravaggio</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>TEST_00003</td>\n      <td>Albrecht Du rer</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>TEST_00004</td>\n      <td>Edgar Degas</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit.head()"
   ],
   "metadata": {
    "id": "15bd98c5d6b59bf4",
    "ExecuteTime": {
     "end_time": "2023-12-27T08:09:53.948111Z",
     "start_time": "2023-12-27T08:09:53.883414700Z"
    }
   },
   "id": "15bd98c5d6b59bf4"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "submit.to_csv(os.path.join(data_path, f\"./submit_{CFG['FILENAME']}.csv\"), index=False)"
   ],
   "metadata": {
    "id": "eed3cb0dc59f47f7",
    "ExecuteTime": {
     "end_time": "2023-12-27T08:09:53.965156600Z",
     "start_time": "2023-12-27T08:09:53.897952200Z"
    }
   },
   "id": "eed3cb0dc59f47f7"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [],
   "metadata": {
    "id": "d3ed2b836c4e558b",
    "ExecuteTime": {
     "end_time": "2023-12-27T08:09:53.966155500Z",
     "start_time": "2023-12-27T08:09:53.929551700Z"
    }
   },
   "id": "d3ed2b836c4e558b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
